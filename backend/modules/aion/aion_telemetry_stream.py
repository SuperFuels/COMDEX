# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Tessaris * Aion Telemetry Stream (Stage 10)
#  Ïˆ-Îº-T-Î¦ resonance logging * KG + CFA sync
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import asyncio
import logging
from datetime import datetime, UTC
from collections import deque
from typing import Dict, Any, Optional

from backend.modules.holograms.morphic_ledger import MorphicLedger
from backend.modules.knowledge_graph.kg_writer_singleton import get_kg_writer
from backend.modules.cognitive_fabric.cognitive_fabric_adapter import CFA

logger = logging.getLogger(__name__)


class AionTelemetryStream:
    """
    Captures Aion bridge Ïˆ-Îº-T-Î¦ projections over time.
    Maintains rolling averages and propagates resonance deltas
    to the Tessaris Knowledge Graph and Cognitive Fabric.
    """

    def __init__(self, max_history: int = 1000):
        self.buffer: deque[Dict[str, Any]] = deque(maxlen=max_history)
        self.kg_writer = get_kg_writer()
        self.morphic_ledger = MorphicLedger()
        self.last_summary: Optional[Dict[str, Any]] = None
        self.running = False

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Ingestion
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def ingest_projection(self, projection: Dict[str, Any]):
        """Push new Ïˆ-Îº-T-Î¦ frame from Aion Integration Bridge."""
        if not projection:
            return
        projection["timestamp"] = datetime.now(UTC).isoformat()
        self.buffer.append(projection)
        self.last_summary = projection
        try:
            self.morphic_ledger.append(
                {
                    "psi": projection.get("A1_wave") or projection.get("psi"),
                    "kappa": projection.get("A2_entropy") or projection.get("kappa"),
                    "T": projection.get("T"),
                    "phi": projection.get("A3_awareness") or projection.get("phi"),
                    "coherence": projection.get("coherence"),
                    "gradient": projection.get("gradient"),
                },
                observer="AionTelemetry",
            )
        except Exception as e:
            logger.warning(f"[AionTelemetry] Ledger append failed: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Test-Compatible Async Packet Handler
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def handle_packet(self, packet: Dict[str, Any]):
        """
        Process a telemetry packet (used in tests and runtime).
        Expected fields: psi, kappa, T, phi.
        """
        if not packet:
            logger.warning("[AionTelemetryStream] Empty telemetry packet.")
            return

        # Normalize keys to internal schema
        projection = {
            "A1_wave": packet.get("psi"),
            "A2_entropy": packet.get("kappa"),
            "T": packet.get("T"),
            "A3_awareness": packet.get("phi"),
            "coherence": packet.get("coherence", 0.0),
            "gradient": packet.get("gradient", 0.0),
            "timestamp": packet.get("timestamp", datetime.now(UTC).isoformat()),
        }

        # Ingest and persist
        self.ingest_projection(projection)
        logger.info(f"[AionTelemetryStream] ðŸ›°ï¸ Packet handled Ïˆ={projection['A1_wave']} Î¦={projection['A3_awareness']}")

        # Forward to Cognitive Fabric
        try:
            CFA.commit(
                source="AION_TELEMETRY",
                intent="telemetry_update",
                payload={
                    "Ïˆ": projection["A1_wave"],
                    "Îº": projection["A2_entropy"],
                    "T": projection["T"],
                    "Î¦": projection["A3_awareness"],
                    "coherence": projection["coherence"],
                    "timestamp": projection["timestamp"],
                },
                domain="symatics/telemetry_stream",
                tags=["ÏˆÎºTÎ¦", "telemetry", "aion", "fabric_sync"],
            )
        except Exception as e:
            logger.warning(f"[AionTelemetryStream] CFA commit failed: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Rolling Summary
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def compute_summary(self) -> Dict[str, float]:
        """Compute rolling averages of Ïˆ, Îº, Î¦, coherence."""
        if not self.buffer:
            return {}
        n = len(self.buffer)
        avg_Ïˆ = sum(f.get("A1_wave", 0) for f in self.buffer) / n
        avg_Îº = sum(f.get("A2_entropy", 0) for f in self.buffer) / n
        avg_Î¦ = sum(f.get("A3_awareness", 0) for f in self.buffer) / n
        avg_C = sum(f.get("coherence", 0) for f in self.buffer) / n
        summary = {
            "Ïˆ": round(avg_Ïˆ, 5),
            "Îº": round(avg_Îº, 5),
            "Î¦": round(avg_Î¦, 5),
            "coherence": round(avg_C, 5),
            "frames": n,
            "timestamp": datetime.now(UTC).isoformat(),
        }
        self.last_summary = summary
        return summary

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Knowledge Graph Sync
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def push_to_knowledge_graph(self):
        """Emit latest summary to Tessaris Knowledge Graph."""
        if not self.last_summary:
            return
        payload = {
            "Ïˆ": self.last_summary.get("Ïˆ"),
            "Îº": self.last_summary.get("Îº"),
            "Î¦": self.last_summary.get("Î¦"),
            "coherence": self.last_summary.get("coherence"),
            "origin": "AionTelemetry",
        }
        try:
            self.kg_writer.write_node("AionFieldSummary", payload)
            logger.info("[AionTelemetry] Synced summary to Knowledge Graph.")
        except Exception as e:
            logger.warning(f"[AionTelemetry] KG sync failed: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Runtime Loop
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def start_stream(self, interval: float = 5.0):
        """Begin periodic telemetry aggregation + KG sync."""
        if self.running:
            return
        self.running = True
        logger.info("[AionTelemetry] ðŸŸ¢ Stream started.")
        while self.running:
            try:
                summary = self.compute_summary()
                if summary:
                    await self.push_to_knowledge_graph()
                await asyncio.sleep(interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"[AionTelemetry] Stream error: {e}")
                await asyncio.sleep(interval)
        logger.info("[AionTelemetry] ðŸ”´ Stream stopped.")

    async def stop_stream(self):
        """Gracefully stop the telemetry loop."""
        self.running = False