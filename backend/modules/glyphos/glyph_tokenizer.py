# File: backend/modules/glyphos/glyph_tokenizer.py
# ðŸ”£ Tokenizer for parsing raw "symbol" text fields (e.g., "x + 2") into glyph tokens
# Used in pattern matching, SQI scoring, and symbolic reasoning layers

import re
from typing import List, Dict

# â”€â”€â”€ Main Tokenizer Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def tokenize_symbol_text_to_glyphs(text: str) -> List[Dict[str, str]]:
    """
    Converts a raw string like 'x + 2' into structured glyph tokens:
        Input:  "x + 2"
        Output: [
            {'type': 'variable', 'value': 'x'},
            {'type': 'operator', 'value': '+'},
            {'type': 'number', 'value': '2'}
        ]
    """
    tokens: List[Dict[str, str]] = []

    # IMPORTANT: put multi-character tokens first (longest-match wins), then single-char classes.
    # Added Phase-7 symbolic opcodes: âˆ‡ (numeric), âˆ‡c (compress alias), â†”, âŸ², â§–, â†’, âœ¦
    pattern = (
        r"(âˆ‡c|â†”|âŸ²|â§–|â†’|âœ¦|âˆ‡|"                # symbolic multi/single glyph ops (new)
        r"[A-Za-z_]\w*|"                     # identifiers
        r"\d+\.?\d*|"                        # numbers
        r"==|!=|<=|>=|\*\*|"                 # multi-char ASCII ops
        r"[\+\-\*/\^=<>!()]|"                # single-char ASCII ops/parens
        r"[â‰¡âŠ•âŠ—â‰¤â‰¥âˆ§âˆ¨Â¬:,])"                    # other symbolic singles we already supported
    )

    for match in re.finditer(pattern, text):
        token = match.group(0)
        token_type = classify_token(token)
        tokens.append({"type": token_type, "value": token})

    return tokens


# â”€â”€â”€ Helper: Token Classifier â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def classify_token(token: str) -> str:
    """
    Classifies a token as one of: variable, number, operator, paren, function, keyword, string, or unknown.
    """
    # number
    if re.fullmatch(r"\d+\.?\d*", token):
        return "number"

    # string literal
    if re.fullmatch(r"'[^']*'|\"[^\"]*\"", token):
        return "string"

    # keywords
    if token in {"if", "return"}:
        return "keyword"

    # known math functions
    if token in {"sin", "cos", "tan", "log", "exp", "sqrt", "abs"}:
        return "function"

    # identifier / variable
    if re.fullmatch(r"[A-Za-z_]\w*", token):
        return "variable"

    # operators (ASCII + symbolic)
    # Added Phase-7 ops here: âˆ‡, âˆ‡c, â†”, âŸ², â§–, â†’, âœ¦
    if token in {
        # ASCII
        "+", "-", "*", "/", "^", "=", "==", "!=", "<", ">", "<=", ">=", "**",
        # symbolic (existing)
        "âŠ•", "âŠ—", "â‰¡", "â‰¤", "â‰¥", "âˆ§", "âˆ¨", "Â¬",
        # symbolic (new)
        "âˆ‡", "âˆ‡c", "â†”", "âŸ²", "â§–", "â†’", "âœ¦",
    }:
        return "operator"

    # parens
    if token in {"(", ")"}:
        return "paren"

    # punctuation
    if token in {":", ","}:
        return "symbol"

    return "unknown"


# â”€â”€â”€ Optional Preview CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    test_cases = [
        "x + 2",
        "y = mx + b",
        "3.14 * r^2",
        "(a + b) / c",
        "delta != gamma",
        "âŠ•(x, y) â‰¡ z",
        "sin(theta) + cos(phi)",
        "if x > 0: return x**2",
        "overwrite('memory')",
        "x**2 + y**2 == z**2",
        # Phase-7 glyph opcodes
        "âŠ• âˆ‡ â†” âŸ² â§– â†’ âœ¦",
        "âˆ‡c(a, b) â†” c",
    ]

    for case in test_cases:
        print(f"\nðŸ”¤ Input: {case}")
        tokens = tokenize_symbol_text_to_glyphs(case)
        for t in tokens:
            print(f"  - {t['type']:>8}: {t['value']}")