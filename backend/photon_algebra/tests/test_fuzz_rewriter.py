# -*- coding: utf-8 -*-
# File: backend/photon_algebra/tests/test_fuzz_rewriter.py

import json
from hypothesis import given, strategies as st, settings, HealthCheck
from backend.photon_algebra.rewriter import normalize
from backend.photon_algebra.core import EMPTY  # ðŸ”‘ shared canonical empty

# ---------------------------
# Generators
# ---------------------------

# Simple leaf symbols (you can expand later)
leaf = st.sampled_from(list("abcdefghijklmnopqrstuvwxyz"))

def expr_strategy(max_depth: int = 4):
    """Random Photon expressions with bounded depth."""
    if max_depth <= 0:
        return leaf

    # Build recursively
    return st.deferred(lambda: st.one_of(
        # Leaf
        leaf,
        # Unary: Â¬
        st.builds(lambda s: {"op": "Â¬", "state": s}, expr_strategy(max_depth - 1)),
        # Binary ops with fixed arity = 2
        st.builds(lambda a, b: {"op": "âŠ—", "states": [a, b]},
                  expr_strategy(max_depth - 1), expr_strategy(max_depth - 1)),
        st.builds(lambda a, b: {"op": "âŠ–", "states": [a, b]},
                  expr_strategy(max_depth - 1), expr_strategy(max_depth - 1)),
        st.builds(lambda a, b: {"op": "â†”", "states": [a, b]},
                  expr_strategy(max_depth - 1), expr_strategy(max_depth - 1)),
        # N-ary âŠ• (1..4 terms) to exercise flatten/sort/dedupe paths
        st.builds(lambda xs: {"op": "âŠ•", "states": xs},
                  st.lists(expr_strategy(max_depth - 1), min_size=1, max_size=4)),
    ))

rand_expr = expr_strategy(4)

# Aggressive default; can down-tune in CI by HYPOTHESIS_MAX_EXAMPLES env var
DEF_SETTINGS = dict(
    max_examples=1000,
    deadline=None,
    suppress_health_check=[HealthCheck.too_slow],
)

# ---------------------------
# Invariants & Identities
# ---------------------------

@given(expr=rand_expr)
@settings(**DEF_SETTINGS)
def test_normalize_idempotent(expr):
    """normalize(normalize(x)) == normalize(x)"""
    n1 = normalize(expr)
    n2 = normalize(n1)
    assert n1 == n2

@given(expr=rand_expr)
@settings(**DEF_SETTINGS)
def test_normalize_is_deterministic_string(expr):
    """String form of normalized expr is stable across runs."""
    n = normalize(expr)
    s1 = json.dumps(n, sort_keys=True, ensure_ascii=False)
    s2 = json.dumps(normalize(expr), sort_keys=True, ensure_ascii=False)
    assert s1 == s2

@given(a=leaf, b=leaf)
@settings(**DEF_SETTINGS)
def test_commutativity_sample(a, b):
    """a âŠ• b â‰¡ b âŠ• a (after normalize)"""
    e1 = {"op": "âŠ•", "states": [a, b]}
    e2 = {"op": "âŠ•", "states": [b, a]}
    assert normalize(e1) == normalize(e2)

@given(a=leaf, b=leaf, c=leaf)
@settings(**DEF_SETTINGS)
def test_associativity_sample(a, b, c):
    """(a âŠ• b) âŠ• c â‰¡ a âŠ• (b âŠ• c)"""
    e1 = {"op": "âŠ•", "states": [ {"op": "âŠ•", "states": [a, b]}, c ]}
    e2 = {"op": "âŠ•", "states": [ a, {"op": "âŠ•", "states": [b, c]} ]}
    assert normalize(e1) == normalize(e2)

@given(a=leaf, b=leaf, c=leaf)
@settings(**DEF_SETTINGS)
def test_distributivity_sample(a, b, c):
    """a âŠ— (b âŠ• c) â‰¡ (a âŠ— b) âŠ• (a âŠ— c)"""
    left = {"op": "âŠ—", "states": [a, {"op": "âŠ•", "states": [b, c]}]}
    right = {"op": "âŠ•", "states": [
        {"op": "âŠ—", "states": [a, b]},
        {"op": "âŠ—", "states": [a, c]},
    ]}
    assert normalize(left) == normalize(right)

@given(a=leaf)
@settings(**DEF_SETTINGS)
def test_idempotence_sample(a):
    """a âŠ• a â‰¡ a"""
    e = {"op": "âŠ•", "states": [a, a]}
    assert normalize(e) == a

@given(a=leaf)
@settings(**DEF_SETTINGS)
def test_cancellation_sample(a):
    """a âŠ– a â‰¡ âˆ…"""
    e = {"op": "âŠ–", "states": [a, a]}
    assert normalize(e) == EMPTY  # ðŸ”‘ use shared constant

@given(a=leaf)
@settings(**DEF_SETTINGS)
def test_double_negation_sample(a):
    """Â¬(Â¬a) â‰¡ a"""
    e = {"op": "Â¬", "state": {"op": "Â¬", "state": a}}
    assert normalize(e) == a