"""
AION Cognitive Bridge ‚Äî Extended Commands
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Provides live cognitive reasoning and lexical utilities for AION.
"""

import random, difflib, logging
from backend.modules.aion_language.resonant_memory_cache import ResonantMemoryCache

log = logging.getLogger(__name__)

# Safe imports
try:
    import backend.modules.aion_cognition.cee_lex_memory as cee_lex
    LEX = cee_lex.LexMemory() if hasattr(cee_lex, "LexMemory") else None
except Exception as e:
    LEX = None
    log.warning(f"[Bridge] ‚ö† LexMemory unavailable: {e}")

try:
    from backend.modules.aion_cognition.semantic_benchmark import benchmark_runner
except Exception:
    benchmark_runner = None
    log.warning("[Bridge] ‚ö† semantic_benchmark unavailable.")

try:
    from backend.modules.aion_cognition.advanced_cognition import lexical_task_runner
except Exception:
    lexical_task_runner = None
    log.warning("[Bridge] ‚ö† advanced_cognition unavailable.")

RMC = ResonantMemoryCache()

# --- LCE-style interactive helpers ---

def anagram_word(word: str):
    """Return a shuffled form of the word and (optionally) solve it back."""
    if not word or not isinstance(word, str):
        return "‚ö†Ô∏è Provide a single word."
    # if you want a solve: try finding the closest lemma in cache by sorted letters
    target_sorted = "".join(sorted(word.lower()))
    candidates = [w for w in getattr(RMC, "cache", {}).keys() if isinstance(w, str)]
    solved = next((w for w in candidates if "".join(sorted(w.lower())) == target_sorted), None)
    # always return an anagram string (shuffled)
    import random
    chars = list(word)
    random.shuffle(chars)
    jumbled = "".join(chars)
    if solved and solved != word:
        return f"üß© Anagram of '{word}' ‚Üí '{jumbled}'  (solve: {solved})"
    return f"üß© Anagram of '{word}' ‚Üí '{jumbled}'"

def complete_word(word: str):
    """Produce a simple definitional completion cue from LexMemory / RMC."""
    from backend.modules.aion_cognition.cee_lex_memory import recall_from_memory
    lex = recall_from_memory(word) or {}
    definition = lex.get("answer") or lex.get("definition")
    if not definition:
        # try RMC
        entry = RMC.lookup(word) or {}
        definition = entry.get("definition")
    if not definition:
        return f"ü§∑ No stored definition for '{word}'. Try teaching first: teach {word} 2"
    first = definition.split(".", 1)[0].strip()
    return f"‚úçÔ∏è Completion: {word.capitalize()} is‚Ä¶ {first}"

def match_word(word: str):
    """Emit a simple definition-match style prompt from memory."""
    from backend.modules.aion_cognition.cee_lex_memory import recall_from_memory
    lex = recall_from_memory(word) or {}
    definition = lex.get("answer") or lex.get("definition")
    if not definition:
        entry = RMC.lookup(word) or {}
        definition = entry.get("definition")
    if not definition:
        return f"ü§∑ No definition for '{word}'."
    # Build distractors from other cached lemmas
    pool = [k for k in getattr(RMC, "cache", {}).keys() if isinstance(k, str) and k.lower() != word.lower()]
    import random
    distractors = random.sample(pool, min(3, len(pool))) if pool else ["electron", "wave", "field"]
    choices = distractors + [word]
    random.shuffle(choices)
    pretty = "\n".join(f"  {i+1}. {c}" for i, c in enumerate(choices))
    return f"üß† Match the definition:\n‚Äú{definition}‚Äù\nChoices:\n{pretty}\n(answer: {word})"
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Lexical + Symbolic
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def define_word(word: str):
    """Return a concept‚Äôs recalled definition + resonance info (guaranteed fallback)."""
    from backend.modules.aion_cognition.cee_lex_memory import recall_from_memory, _load_memory

    # 1Ô∏è‚É£ Try lexical fuzzy recall
    lex_entry = recall_from_memory(word)
    definition = None
    if lex_entry:
        definition = lex_entry.get("answer") or lex_entry.get("definition")

    # 2Ô∏è‚É£ Try direct key scan if fuzzy recall fails
    if not definition:
        mem = _load_memory()
        for key in mem.keys():
            if key.startswith(f"{word}‚Üî"):
                definition = key.split("‚Üî", 1)[1].strip()
                break

    # 3Ô∏è‚É£ Fallback to ResonantMemoryCache if still undefined
    if not definition:
        if hasattr(RMC, "cache") and word in RMC.cache:
            entry = RMC.cache[word]
            definition = entry.get("definition", f"(learned resonance concept '{word}')")
            resonance = entry.get("resonance", 0.0)
            stability = entry.get("stability", 0.0)
            symbol = entry.get("symbol", "‚àÖ")
            return (
                f"üìò {word}: {definition}\n"
                f"üí° Symbolic: {symbol}\n"
                f"üîÆ Resonance={resonance:.3f}, Stability={stability:.3f}"
            )
        return f"‚ùå No definition found for '{word}'."

    # 4Ô∏è‚É£ Merge with RMC resonance metadata if available
    entry = getattr(RMC, "cache", {}).get(word, {})
    resonance = entry.get("resonance", 0.0)
    stability = entry.get("stability", 0.0)
    symbol = entry.get("symbol", "‚àÖ")

    # 5Ô∏è‚É£ Final display
    return (
        f"üìò {word}: {definition}\n"
        f"üí° Symbolic: {symbol}\n"
        f"üîÆ Resonance={resonance:.3f}, Stability={stability:.3f}"
    )


def symbol_word(word: str):
    """Return symbolic photon/QMath representation for a word."""
    entry = None

    if hasattr(RMC, "cache") and word in getattr(RMC, "cache", {}):
        entry = RMC.cache[word]
    elif hasattr(RMC, "recall"):
        try:
            entry = RMC.recall(word)
        except Exception:
            entry = None

    if not entry:
        return f"‚ö†Ô∏è No symbolic tensor for '{word}'."

    symbol = entry.get("symbol", None)
    if not symbol:
        return f"üí° {word}: (symbolic tensor undefined)"
    return f"üí° Symbolic QMath({word}) ‚Üí {symbol}"


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Wordplay + Semantic reasoning
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def unjumble_word(letters: str):
    """Attempt to unscramble letters to nearest known lemma."""
    candidates = []
    if LEX and hasattr(LEX, "cache"):
        candidates = list(LEX.cache.keys())
    elif hasattr(RMC, "cache"):
        candidates = list(RMC.cache.keys())

    match = difflib.get_close_matches(letters, candidates, n=1, cutoff=0.5)
    if match:
        return f"üß© Unjumble ‚Üí '{letters}' = '{match[0]}'"
    return f"‚ùå No matching lemma for '{letters}'"


def compare_words(w1: str, w2: str):
    """Compare two words semantically (Meaning Consistency Index)."""
    if not benchmark_runner or not hasattr(benchmark_runner, "compare_pair"):
        return "‚ö†Ô∏è Semantic benchmark unavailable."
    result = benchmark_runner.compare_pair(w1, w2)
    if not result:
        return f"‚ö†Ô∏è Unable to compare '{w1}' and '{w2}'."
    mci = round(result.get("MCI", 0.0), 3)
    sim = round(result.get("similarity", 0.0), 3)
    return f"üîç Compare '{w1}' ‚Üî '{w2}' ‚Üí MCI={mci}, sim={sim}"


def context_word(word: str, phrase: str):
    """Evaluate a word‚Äôs meaning stability within a phrase."""
    if not benchmark_runner or not hasattr(benchmark_runner, "context_eval"):
        return "‚ö†Ô∏è Contextual benchmark unavailable."
    result = benchmark_runner.context_eval(word, phrase)
    if not result:
        return f"‚ö†Ô∏è No contextual data for '{word}' in '{phrase}'."
    mci = round(result.get("MCI", 0.0), 3)
    drift = round(result.get("drift", 0.0), 3)
    return f"üß† Context('{word}' in '{phrase}') ‚Üí MCI={mci}, drift={drift}"


def connect_concepts(chain: str):
    """Link related concepts in the resonance graph."""
    nodes = [x.strip() for x in chain.replace("‚Üí", "->").split("->") if x.strip()]
    if len(nodes) < 2:
        return "‚ö†Ô∏è Need at least two concepts to connect."
    for i in range(len(nodes) - 1):
        try:
            RMC.link(nodes[i], nodes[i + 1])
        except Exception:
            pass
    return f"üîó Connected: {' ‚Üí '.join(nodes)}"


def stats_summary():
    """Return compact cognitive metrics snapshot."""
    try:
        s = RMC.get_summary()
    except Exception:
        s = {"avg_SQI": 0, "avg_stability": 0, "avg_MCI": 0}
    return (
        f"üìä SQI={round(s.get('avg_SQI', 0), 3)}, "
        f"Stability={round(s.get('avg_stability', 0), 3)}, "
        f"MCI={round(s.get('avg_MCI', 0), 3)}"
    )

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Resonant Field Visualization (new)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def map_resonance_field(concept: str = "general"):
    """
    Visualize the resonance field connections for a given concept.
    Usage: Aionüß†> map resonance field [concept]
    """
    try:
        from backend.modules.aion_language.resonant_memory_cache import ResonantMemoryCache
        from backend.modules.visualization.resonance_field_mapper import plot_resonance_field
    except ImportError:
        return "‚ö†Ô∏è Visualization module unavailable (missing resonance_field_mapper)."

    cache = ResonantMemoryCache()
    field_data = cache.query_field(concept)
    if not field_data:
        return f"‚ùå No resonance data found for '{concept}'."
    plot_resonance_field(field_data)
    return f"üß≠ Resonance field mapped for '{concept}'."