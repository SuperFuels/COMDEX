# Photon / Glyph Image Compression – Notes

_Last updated: 2025-12-12_

## 1. Motivation

Traditional images are stored as huge grids of raw numbers:

- Each pixel = (R, G, B)
- Each channel often = 8 bits → 24 bits per pixel
- Files are massive because we store **every pixel’s raw value** (even if lots of it is repetitive or structured)

In our stack we have:

- **Photon Algebra** – higher-level symbolic operations (wave, resonance, fields, etc.)
- **Glyphs** – symbols that can encode meaning, patterns, or instructions

The idea:  
Can we represent an image as a **photon/glyph program**, instead of a giant raw matrix of RGB values, to get:

- Much better compression
- Fast decode on a photon-native runtime
- A representation that fits the “wave / field / resonance” worldview

---

## 2. Binary vs Photon: What Actually Changes?

### Binary today

- **Substrate:** electrons in silicon
- **States:** voltage low/high → 0/1
- **Encoding:** numbers (0–255 per channel), arrays of bytes
- **Images:** 2D array of (R,G,B) values

### Photon / glyph architecture

- **Substrate:** photons / resonance instead of electrons
- **States:** presence/absence of light, phase, polarization, wavelength
- **Encoding:** glyphs and photon algebra instructions
- **Images:** **programs** made of visual primitives / fields, not raw pixels

**Important:**  
Even if the substrate changes (electrons → photons), information theory still holds.  
Just renaming bits to glyphs doesn’t reduce entropy. Compression comes from structure.

---

## 3. Naive RGB → Glyph Mapping (Why It Doesn’t Help)

Example idea:

> R = ⬢, G = ✱, B = ✩

If we do this naively:

- For each pixel:
  - Store ⬢ + value for R
  - Store ✱ + value for G
  - Store ✩ + value for B

Then:

- We still store **3 numbers per pixel**
- We still need ~24 bits/pixel for arbitrary colors
- Shannon’s math doesn’t care whether the alphabet is `0/1` or `⬢/✱/✩`

Conclusion:

> A 1:1 glyph replacement for raw RGB is **just a skin change**, not real compression.

---

## 4. Where Real Compression Appears

The idea becomes powerful when:

> **One glyph no longer means “one channel value”, but “one structured visual primitive”.**

Examples of what a single glyph could mean:

- `⬢` – “sky gradient preset #17 (light blue → darker blue)”
- `✱` – “skin tone palette S4”
- `✩` – “starfield texture T1 with density D”

Then an image is NOT:

- Billions of `[R,G,B]` triples

It is more like:

```photon
image {
  region ⬢:
    gradient(palette = sky_blue_17, from = top, to = 0.6h)

  region ✱:
    polygon(mask = face_outline)
    fill(palette = S4, shading = soft)

  region ✩:
    scatter(texture = starfield_T1, density = 0.12, area = sky_region)
}

Now compression comes from:
	•	Fewer tokens:
Hundreds of instructions instead of millions of pixels
	•	Reuse of motifs:
Same palettes, textures, gradients reused in many places
	•	Procedural detail:
Fine detail regenerated by photon/wave operations instead of stored explicitly

This is conceptually similar to:
	•	Vector graphics (draw shapes, not pixels)
	•	Shaders (program that draws a surface)
	•	Codecs (JPEG, video) that encode patterns/blocks instead of raw pixels

But here the “language” is Photon / Glyph Algebra instead of DCT/motion vectors.

⸻

5. Photon / Glyph-Friendly Structure

A photon/glyph image format (.phimg or similar) could have:
	1.	Palette & motif tables
	•	Named color fields, gradients, textures, noise fields, etc.
	2.	Region definitions
	•	Masks (polygons, splines, SDFs)
	•	“Apply motif X to region Y with parameters Z”
	3.	Wavefield instructions
	•	“Create field F(x,y) with these harmonics”
	•	“Interfere F1 and F2 with operator ⊕”
	•	“Apply blur/sharpen as a wave operator (not pixel kernel)”
	4.	Glyph metadata
	•	Symbolic tags: sky, face, text, foreground, etc.

⸻

6. Why This Fits Photon Algebra

Photon Algebra is about:
	•	Waves, fields, interference, resonance, collapse
	•	Operations that naturally map to continuous structures

Visual content is also:
	•	Gradients, textures, edges, blobs, repeated motifs
	•	Very wave-like by nature

So a photon-native image system can:
	•	Treat an image as a field reconstructed by algebraic operations
	•	Store parameters + glyphs, not brute-force samples
	•	Use wave operations for:
	•	Up/down-scaling
	•	Filtering
	•	Procedural detail generation
	•	Compression/decompression

⸻

7. Photon vs Binary: Where the Win Actually Is

Changing the substrate:
	•	Not enough:
Photon hardware alone does NOT magically compress images.

Changing the representation:
	•	Where the magic is:
Describing images as photon/glyph programs instead of raw pixel matrices.

So in short:

The win isn’t “photon beats binary”.
The win is “glyph program beats raw RGB”, and photon hardware just happens to be a native runtime for that program.

⸻

8. Summary (for Future You)
	•	Naive “RGB → glyph per channel” ≈ no real compression, just a different alphabet.
	•	Real compression comes when glyphs encode structured primitives:
	•	Regions, palettes, fields, textures, and wave operations.
	•	A photon-native machine is ideal for this because:
	•	The core operations (interference, resonance, filtering) are literally the hardware’s natural behavior.
	•	Long-term direction:
	•	Define a .phimg (or similar) format that:
	•	Stores images as photon/glyph programs
	•	Uses a library of reusable visual motifs
	•	Reconstructs final pixels only at the edge (display / legacy systems)

This document = parking lot for the idea:

“Use Photon / Glyph Algebra to turn images into wave programs, not pixel grids.”