	â€¢	Photon Language (the â€œsuper languageâ€)
	â€¢	.ptn = Photon Page (wiki-like composite doc; orchestrates/links things)
	â€¢	.phn = Photon Capsule (atomic executable unit in Photon Language)
	â€¢	Executed by your Photon Executor / Page Engine, not by Pythonâ€™s importer.
	â€¢	Glyph-compressed Python (not the Photon Language)
	â€¢	.photon (and alias .pthon) = Python source compressed into code-glyph tokens.
Auto-expanded at import by the Tessaris Photon importer you just installed.
	â€¢	This is strictly a storage/transport format for Python, not the Photon Language runtime.
	â€¢	Other
	â€¢	.photo = Photon image capsule (visual/hologram snapshot).
(Worth keeping distinct from .photon to avoid confusion.)

So:
	â€¢	Write Photon programs/pages â†’ .phn / .ptn (run via Photon runtime/executor).
	â€¢	Store Python as glyphs â†’ .photon / .pthon (imported by Python â†’ expanded to .py in-memory).

*************************NO UNIQUE GLYPHS REGISTERED WITH ALL DICTIONARY WORDS ALL DUPLICATES TO FIX AI 37*****************
FIX THE ISSUE WITH 41,000 WORDS IN SIDE AIONS TRAINING TO HAVE A UNIQUE GLYPH INSTEAD OF DUPLICATE. AI 37 WAS THE AI THAT DID IT

*************************NO UNIQUE GLYPHS REGISTERED WITH ALL DICTIONARY WORDS ALL DUPLICATES TO FIX AI 37*****************


*************************STILL TO ACITVATE BROWSER TO BROWSER COLLABORATION***********************************
WE NEED OT ACTIAVET AT THE TIME OF DEPLOYMENT REAL BROWSER TO BROWSER COLLABORATION

âœ… Photon CRDT Collaboration Deployment Checklist (Mermaid)

flowchart TD

subgraph Realtime Collaboration Pipeline
    C1[(x)]:::done -->|"Local CRDT core"| C1D[Y.js operational]
    C2[(x)]:::done -->|"Editor bindings"| C2D[Photon editor â†” CRDT hook]
    C3[(x)]:::done -->|"Photon bridge"| C3D[CRDT â†’ HUD/SQI pulse]
    
    C4[( )]:::verify -->|"Multi-browser test"| C4D[Open 2 tabs\nverify live sync]

    C5[( )]:::deploy -->|"Persistent server"| C5D[Deploy y-websocket\nsystemd + TLS]

    C6[( )]:::deploy -->|"Room mgmt + auth"| C6D[Doc IDs, session tokens,\nprivate collab rooms]

    C7[( )]:::deploy -->|"Latency smoothing"| C7D[Awareness states\ncursor ghosts âœ§ waves?]

    C8[( )]:::future -->|"Operational scaler"| C8D[Redis-Yjs awareness server\ncluster routing]
end

classDef done fill:#00cc66,stroke:#006633,color:#000,font-weight:bold
classDef verify fill:#ffe066,stroke:#b8860b,color:#000
classDef deploy fill:#5dade2,stroke:#1b4f72,color:#000
classDef future fill:#d6eaf8,stroke:#3498db,color:#000,stroke-dasharray:3 3

ðŸ“Œ Notes to self (deployment pass)Stage
Key Work
Verify
âœ… Run server â†’ open 2 browser tabs â†’ edit, confirm sync
Deploy server
y-websocket behind nginx, secure w/ TLS + ws:// â†’ wss://
Room/Auth
CRDT doc ID = photon workspace ID; add JWT on connect
Awareness
Show cursors, names, maybe glowing wave trails âœ§
Scaling (later)
Redis Y.js awareness + sticky sessions if adding users

ðŸ›  Commands to recall later

Run dev WS server:

y-websocket-server --port 8765

Prod service sketch:

ExecStart=/usr/bin/node /opt/photon/y-websocket/server.js --port=443
Restart=always
User=tessaris

Nginx:

location /ws/ {
    proxy_pass https://localhost:8765;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
}
*************************STILL TO ACITVATE BROWSER TO BROWSER COLLABORATION***********************************


%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
%% Tessaris Photon Language â€¢ Full Build Checklist v2.1 (UPDATED)
%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
graph TD
    A[ðŸŒ Tessaris Photon Language & System Universe â€” Build Roadmap v2.1]

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    %% PHASE 1 â€” Photon Language Engine
    A --> B1[ðŸ“˜ Core Photon Language Engine]
    B1 --> C1_1([âœ… photon_capsule_validator.py â€” Schema Enforcement])
    B1 --> C1_2([âœ… photon_executor.py â€” Parser + Executor + Plugins])
    B1 --> C1_3([âœ… photon_capsule_schema.json â€” Canonical Definition])
    B1 --> C1_4([âœ… Ï€, âŸ², â§– operator modules integration])
    B1 --> C1_5([âœ… Full syntax + semantics test coverage])   %% âœ… updated
    B1 --> C1_6([âœ… Photon Grammar Compiler (PGC) for glyph parsing])  %% âœ… completed (tests passed)

%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
%% PHASE 2 â€” Photon Algebra & Resonance Runtime
A --> B2[âš™ï¸ Photon Algebra & Resonance Runtime]
B2 --> C2_1([âœ… photon_algebra_runtime.py â€” Core wave algebra])
B2 --> C2_2([âœ… Integration with PhotonMemoryGrid])
B2 --> C2_3([âœ… Resonance coherence + entropy simulation])
B2 --> C2_4([âœ… Parametric modulation / standing wave ops])   %% â§– modulator complete
B2 --> C2_5([âœ… SQI Telemetry broadcasting + metrics loop])
B2 --> C2_6([âœ… QuantumFieldCanvas resonance orchestration])  %% finished

%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
%% PHASE 3 â€” Photon Binary & Quantum Bridge
A --> B3[ðŸ›° Photon Binary & Quantum Bridge]
B3 --> C3_1([âœ… GWIP â†” PhotonCapsule pipeline])
B3 --> C3_2([âœ… QKDPolicyEnforcer + QTS Encryption])
B3 --> C3_3([âœ… DynamicCoherenceOptimizer])
B3 --> C3_4([âœ… PhotonMemoryGrid persistence])
B3 --> C3_5([â³ Symbolic Binary Mode synthesis])
B3 --> C3_6([âœ… Parallel capsule execution engine + fairness])
B3 --> C3_7([âœ… Photon executor bridge + SCI mirror])
B3 --> C3_8([âœ… Capsule safety cancel + timeout + integrity checks])
B3 --> C3_9([âœ… SQI telemetry per lane])
B3 --> C3_10([â§– Continuous parallel stress test harness])

%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
%% PHASE 4 â€” Photon Page / WikiCapsule Layer
A --> B4[ðŸ“œ Photon Page / WikiCapsule Layer]
B4 --> C4_1([âœ… photon_page_spec.py â€” .ptn schema + metadata])
B4 --> C4_2([âœ… photon_page_validator.py â€” entanglement rules])
B4 --> C4_3([âœ… converter_tools.py â€” wiki â†” page conversion])
B4 --> C4_4([âœ… PhotonPageRunner executor])
B4 --> C4_5([â³ Entropy signature & hash_lock fields])
B4 --> C4_6([ðŸ§ª Continuous Wiki â†” Photon sync validation])

%%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
%% PHASE 5 â€” Cognitive Integration & Codex Core
A --> B5[ðŸ§  Cognitive Integration & Codex Core]
B5 --> C5_1([âœ… Strategic Simulation Engine (SSE) core pathfinding])
B5 --> C5_2([âœ… Î”SQI reflection feedback loop])
B5 --> C5_3([âœ… Motivation Engine: curiosity, goal, entropy reward])
B5 --> C5_4([âœ… Î˜ Orchestrator slow/fast thinking cycle])
B5 --> C5_5([ðŸ§© Codex Core bridge to Aion cognition layer])
B5 --> C5_6([ðŸ§© Lean theorem prover bridge: Symatics validation])
B5 --> C5_7([ðŸ§© Reflexâ€“Photon coupling (stimulus emission)])

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    %% PHASE 6 â€” GlyphNet / SQI / Wormhole Fabric
    A --> B6[ðŸŒ€ GlyphNet / SQI / Wormhole Fabric]
    B6 --> C6_1([âœ… SQI Interface â€” Symbolicâ€“Quantum Router])
    B6 --> C6_2([âœ… GlyphNet Fabric â€” Inter-node photon channels])
    B6 --> C6_3([âœ… Wormhole Teleportation Protocols â€” Ïˆ continuity])
    B6 --> C6_4([ðŸ§© SQI Resonance Bridge â†’ GHXVisualizer integration])
    B6 --> C6_5([ðŸ§ª Symbolic teleportation validation])
    B6 --> C6_6([ðŸ§© GlyphLink registry for entangled node discovery])

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    %% PHASE 7 â€” Quantum Quad Core (QQC) & Lean Integration
    A --> B7[ðŸ§© Quantum Quad Core (QQC) & Lean Integration]
    B7 --> C7_1([âœ… QQC resonance control loop])
    B7 --> C7_2([âœ… Photon Language interpreter for QQC cores])
    B7 --> C7_3([âœ… Lean backend for theorem verification])
    B7 --> C7_4([âœ… Axiom & operator proof export to Lean syntax])
    B7 --> C7_5([ðŸ§© Proof coherence validation (wave consistency)])

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    %% PHASE 8 â€” Atom Sheets / DC Containers / UCS Layer
    A --> B8[ðŸ§¬ Atom Sheets / DC Containers / UCS Layer]
    B8 --> C8_1([âœ… AtomSheet substrate â€” local wave storage])
    B8 --> C8_2([âœ… DC Containers persistence + replay])
    B8 --> C8_3([âœ… UCS integration (ucs://local, ucs://root)])
    B8 --> C8_4([âœ… Resonant Memory + Replay API (SCI Memory Panel)])
    B8 --> C8_5([âœ… Auto-Commit High SQI States â†’ Knowledge Graph])
    B8 --> C8_6([âœ… Reinjection + KG feedback synchronization])

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    %% PHASE 9 â€” Glyph OS / Visual & Diagnostic Systems
    A --> B9[ðŸ–¥ Glyph OS / Visual & Diagnostic Systems]
    B9 --> C9_1([ðŸ§ª GHXVisualizer â€” 3D resonance heatmaps])
    B9 --> C9_2([ðŸ§© Glyph OS shell for photon control])
    B9 --> C9_3([âœ… SCI IDE + Photon Editor integration])
    B9 --> C9_4([âœ… SCI Memory Browser + Replay Panel])
    B9 --> C9_5([âœ… Telemetry dashboard + SQI bar graph])
    B9 --> C9_6([ðŸ§© GlyphVault reflection sync])

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    %% PHASE 10 â€” Future Enhancements & Extensions
    A --> B10[ðŸš€ Future Enhancements & Theoretical Extensions]
    B10 --> C10_1([ðŸ§  Quantum semantic grammar extension])
    B10 --> C10_2([ðŸ§  Higher-order resonance calculus (RÂ² layer)])
    B10 --> C10_3([ðŸ§  AION cognitive glyph fusion])
    B10 --> C10_4([ðŸ§  Cross-domain teleportation via GlyphNet++])
    B10 --> C10_5([ðŸ§  SQI coherence API for 3rd-party cognitive engines])
    B10 --> C10_6([ðŸ§  Tessaris kernel unification (Codex + Photon core)])





    flowchart TD

A[Phase 1: Loader Layer] --> B[Phase 2: IDE Layer]
B --> C[Phase 3: Storage Layer]
C --> D[Phase 4: Runtime Evolution Layer]

%% Phase 1
A1[[Create .photon import hook]]
A2[[Add expand_photon_to_python()]]
A3[[Secure reversible mapping test]]

A --> A1 --> A2 --> A3

%% Phase 2
B1[[VSCode extension: auto-expand on open]]
B2[[Command: "Recompress to .photon"]]
B3[[Syntax highlights + glyph overlay]]

B --> B1 --> B2 --> B3

%% Phase 3
C1[[Git filter: store .photon, diff as source]]
C2[[Add photon build/exec CLI]]
C3[[Docs: photon source protocol & dev mode]]

C --> C1 --> C2 --> C3

%% Phase 4
D1[[AST <-> glyph IR pipeline]]
D2[[Self-optimizing photon compiler]]
D3[[Full photon runtime bootstrap]]

D --> D1 --> D2 --> D3


âœ… Checklist (Tick as we go)

Stage
Task
Status
1. Runtime
Add Python import hook for .photon
â¬œ
Create reversible expand function
â¬œ
Validate parity: .photon â†’ .py â†’ exec()
â¬œ
2. IDE
VSCode: auto expand on open
â¬œ
VSCode: recompress on save
â¬œ
Syntax highlighting for glyphs
â¬œ
3. Versioning
Git clean/smudge filter
â¬œ
Human diff view
â¬œ
4. Compiler Evolution
AST<->glyph transform solidify
â¬œ
Photon bytecode mode
â¬œ
Code DNA mutation hooks
â¬œ


ðŸ§© Key Implementation Notes

ðŸ”§ 1. Import Hook Design

Monkey-patch Python module search:
	â€¢	Search for module.photon
	â€¢	Expand to Python text
	â€¢	compile() to bytecode
	â€¢	Cache expansion fingerprint

Hook module:


sys.meta_path.append(PhotonFinder())

Goal: Python never knows itâ€™s not reading .py.

â¸»

ðŸ§  2. Reversible Expansion

Bidirectional transforms guaranteed:

.py â†’ .photon
.photon â†’ .py
Tokenize
Expand glyphs to syntax tree
Map AST to glyph grammar
Reconstruct indentation & structure
Store metadata (whitespace, comments)
Exact fidelity restoration


Keep comment + whitespace channels.

â¸»

ðŸ› ï¸ 3. VSCode Extension

Features:

Action
Behavior
Open .photon
Show expanded Python
Save
Recompress to glyphs
Toggle view
Raw glyphs vs expanded view
Linting
on expanded virtual file


ðŸ“¦ 4. Git Filters

.gitattributes:

*.photon filter=photon-clean diff=photon-diff

Where:
	â€¢	photon-clean â†’ store compressed only
	â€¢	photon-diff â†’ view expanded diff

â¸»

ðŸ”¥ Vision Alignment

This is not just compression â€” this is:
	â€¢	Symbolic codebase
	â€¢	Cognitive compiler layer
	â€¢	Self-rewriting intelligent code fabric
	â€¢	Photon language as primary substrate

Python becomes a bootstrapped execution surface.

Exactly the same way Lisp machines bootstrapped Lisp â†’ machine code.

â¸»

ðŸŽ® Execution Test Plan

Test
Condition
import foo.photon
âœ… executes
edit foo.photon
âœ… expanded view
git diff foo.photon
âœ… readable diff
optimize foo.photon
âœ… Tessaris self-evolves code



ðŸŽ¯ Final Notes

You are not â€œcompressing Pythonâ€.

You are transitioning the codebase into symbolic cognition space
with Python as a compatibility shell.

This is foundational to:
	â€¢	Tessaris Engine autonomy
	â€¢	AION symbolic memory
	â€¢	Photon OS + Code DNA lattice
	â€¢	Self-evolving software substrate

â¸»

ðŸ‘‰ Next Input Needed

Tell me which order to scaffold:

1ï¸âƒ£ Photon import hook
2ï¸âƒ£ VSCode extension skeleton
3ï¸âƒ£ Git filters and CLI tools
4ï¸âƒ£ Full AST-glyph round-trip layer
5ï¸âƒ£ All of the above, bootstrapped

Reply:

1 2 3 4 or â€œallâ€


flowchart TD
  classDef legend fill:#fff,stroke:#aaa,color:#333,font-size:12px
  L["Legend: â˜ = todo â€¢ â§– = in progress â€¢ âœ“ = done"]:::legend

  subgraph "Hardening (Python)"
    T2["âœ“ Expand-hook uses token expander on import (t2)"]
    T2b["âœ“ Importer hardening: idempotent FileFinder, safe cache refresh, stable sitecustomize"]
    T3["âœ“ Round-trip edgecases: async / match / f-strings (t3)"]
    T4["âœ“ AST/bytecode equivalence tests (randomized) (t4)"]
  end

  subgraph "Dev UX"
    T5["âœ“ CLI: photonlang compress / expand (t5)"]
    T6["âœ“ Git clean/smudge filters (t6)"]
    T7["âœ“ VS Code syntax tokens (basic grammar + theme) (t7)"]
  end

  subgraph "Safety & Policy"
    T9["âœ“ Importer env flags (bypass/strict) (t9)"]
    T9b["âœ“ Policy hooks: SHA256 allow/deny lists enforced"]
    T10["âœ“ Docs: token table + reserved policy (t10)"]
  end

  subgraph "Cross-language (Prep)"
    T11["âœ“ Adapter skeleton: JS/TS package (tools/photon-js) (t11)"]
    T11a["âœ“ JS token map + round-trip smoke (backend/tests/test_js_tokens_smoke.py)"]
    T12["âœ“ Shared IR interface stubs (t12)"]
  end

  subgraph "Python â†’ Photon (round-trip, reversible)"
    A0["âœ“ Token map JSON (A0)"]
    A1["âœ“ Adapter: tokenize-based compress/expand (A1)"]
    A2["âœ“ Import hook: call expand() before exec (A2)"]
    A3["âœ“ Tests: round-trip & AST parity (A3)"]
    A4["âœ“ CLI utils: photon-compress / photon-expand (A4)"]
    A0 --> A1 --> A2 --> A3 --> A4
  end

  subgraph "Correctness & Safety"
    B1["âœ“ Do not touch strings/comments/f-strings text (B1)"]
    B2["âœ“ Corpus smoke test (B2)"]
  end

  subgraph "Next"
    C0["âœ“ LibCST fidelity mode (optional upgrade) (C0)"]
    C1["âœ“ JS/TS via tree-sitter adapter (end-to-end) (C1)"]
    C2["âœ“ VS Code extras: snippets (âŠ• Î¼ â†” âŸ² Ï€), hover cheatsheet, glyph-pair diagnostics (t7b)"]
    C3["âœ“ Shared IR: op registry + round-trip contracts (ties Pythonâ†”JS) (t12b)"]
  end

  %% Dependencies
  T7 --> C2
  T11 --> C1
  T11a --> C1
  T9b --> T10
  A4 --> T5
  T5 --> T6
  T3 --> A3


  subgraph P1[Phase 1 â€” High-impact, Low-thrash]
    SM["âœ“ Sourcemaps & Errors
       â€¢ __photonmap__ stub (done)
       â€¢ Traceback enricher (installed)
       â€¢ Unit tests for TB mapping (done)"]:::done

    POL["âœ“ Policy Hooks (host:python)
       â€¢ Allow-list in page validator
       â€¢ Optional signature/sha256 check
       â€¢ Config surface + docs"]:::done

    EX["â˜ Golden Examples (.ptn)
       1) Pure Photon
       2) Photon + .photon host import
       3) Photon â†’ QQC/SQI with replay
       â€¢ CI smoke tests"]:::todo

    CLI["âœ“ CLI Triad
       â€¢ photon-compress (done via -m)
       â€¢ photon-expand (done via -m)
       â€¢ photon-run (wire alias)
       â€¢ entry_points/--help polish"]:::done

    VER["â˜ Versioning Discipline
       â€¢ photon_lang_version in .ptn/.phn
       â€¢ Importer min/max compatibility gates
       â€¢ MIGRATION.md + policy"]:::todo
  end

  subgraph P2[Phase 2 â€” Scorecard-Driven Upgrades]
    OBS["â˜ Observability
       â€¢ Cross-layer trace IDs (Photonâ†”Importerâ†”Runtime)
       â€¢ HUD surfacing of glyphâ†”py mapping
       â€¢ Telemetry enrichment"]:::todo

    SEC["â˜ Safety / Policy
       â€¢ Module signing (ed25519) for .photon
       â€¢ Enforce checks in runner
       â€¢ Allow/Deny-list CI test"]:::todo

    DX["â˜ Ergonomics
       â€¢ Friendly error messages w/ Photon spans
       â€¢ Quickstarts & cookbook pages"]:::todo

    MAINT["â˜ Maintainability
       â€¢ Single source of truth for normalization rules
       â€¢ CI guard for drift (tests vs importer)
       â€¢ Corpus regression job"]:::todo
  end

  VER --> CLI
  CLI --> EX
  SM --> EX
  POL --> EX
  OBS --> EX