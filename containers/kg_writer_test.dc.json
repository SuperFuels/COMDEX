{
  "id": "kg_writer_test",
  "type": "sourcecode",
  "format": "codexlang",
  "entrypoint": "main",
  "source": "# -*- coding: utf-8 -*-\n\"\"\"\n\ud83d\udcc4 knowledge_graph_writer.py\n\n\ud83e\udde0 Knowledge Graph Writer (CRDT + Entanglement Locks + Conflict Handling)\nInjects symbolic glyphs (memory, reflection, predictions, events) into active `.dc` containers.\nAdds multi-agent CRDT merge, entanglement locks, and conflict glyph tagging.\n\nDesign Rubric:\n- \ud83e\udde0 Symbolic Glyph Type/Role ............... \u2705\n- \ud83d\udce9 Intent + Reason + Trigger Metadata ..... \u2705\n- \ud83d\udce6 Container Context + Coord Awareness .... \u2705\n- \u23f1\ufe0f Timestamp + Runtime Trace Binding ...... \u2705\n- \ud83e\udde9 Plugin & Forecast Integration ...........\u2705\n- \ud83d\udd01 Self-Reflection + Thought Tracing ...... \u2705\n- \ud83d\udcca Validator: Stats, Search, DC Export .... \u2705\n- \ud83c\udf10 CRDT & Entanglement Locks .............. \u2705\n\"\"\"\nimport importlib\nimport os, json\nimport datetime\nfrom pathlib import Path\nfrom typing import Optional, Dict, Any, Tuple, List\nfrom collections import defaultdict\n\ntry:\n    # preferred path resolver\n    from backend.modules.dna_chain.dc_handler import get_dc_path\nexcept Exception:\n    get_dc_path = None\n\n# \u2705 Correct utility imports\nfrom backend.modules.knowledge_graph.id_utils import generate_uuid\nfrom backend.modules.knowledge_graph.time_utils import get_current_timestamp\nfrom backend.modules.sqi.sqi_metadata_embedder import bake_hologram_meta, make_kg_payload\nfrom backend.modules.knowledge_graph.sqi_fastmap_index import sqi_fastmap\nfrom backend.modules.dimensions.containers.container_loader import load_decrypted_container\nfrom backend.modules.dimensions.universal_container_system.ucs_runtime import ucs_runtime\nfrom backend.modules.knowledge_graph.indexes.trace_index import inject_trace_event\nfrom backend.modules.codex.codex_metrics import codex_metrics\n\n# \u2705 Knowledge graph and indexing\nfrom backend.modules.dna_chain.container_index_writer import add_to_index\n\n# HOV integration (adds hover/collapse + viz hints + lazy expansion)\nfrom backend.modules.sqi.sqi_metadata_embedder import (\n    bake_hologram_meta,\n    make_kg_payload,\n)\n\n# Where KG exports will be written (mirrors boot_loader defaults)\n# --- KG export location (persistent) ---\n_REPO_ROOT = Path(__file__).resolve().parents[3]\nKG_EXPORTS_DIR = _REPO_ROOT / \"backend\" / \"modules\" / \"dimensions\" / \"containers\" / \"kg_exports\"\nKG_EXPORTS_DIR.mkdir(parents=True, exist_ok=True)\n_KG_BUSY = False\n\n# --- add near the top of the file (after imports) ---\n_EPHEMERAL_CONTAINER = {\"id\": \"kg_cli_ephemeral\", \"glyph_grid\": [], \"last_updated\": None}\nENABLE_WS_BROADCAST = os.getenv(\"AION_ENABLE_WS_BROADCAST\", \"1\") == \"1\"\n\ndef get_active_container():\n    \"\"\"\n    Try to fetch the active container from state_manager.\n    In CLI or test contexts (no server running), fall back to an in-memory container.\n    \"\"\"\n    try:\n        sm = importlib.import_module(\"backend.modules.consciousness.state_manager\")\n        ucs = sm.get_active_universal_container_system()\n        return ucs.get(\"active_container\", _EPHEMERAL_CONTAINER)\n    except Exception:\n        # CLI/test mode: no UCS \u2013 return ephemeral container so inject_glyph still works\n        return _EPHEMERAL_CONTAINER\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Lazy WS helpers (avoid circular import)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef lazy_broadcast_anchor_update(*args, **kwargs):\n    from backend.routes.ws.glyphnet_ws import broadcast_anchor_update  # Lazy import\n    return broadcast_anchor_update(*args, **kwargs)\n\ndef lazy_broadcast_event(payload: Dict[str, Any]):\n    from backend.routes.ws.glyphnet_ws import broadcast_event  # Lazy import\n    return broadcast_event(payload)\n\n# Safe task creator for optional async WS calls\ndef _safe_emit(coro_or_none):\n    try:\n        import inspect, asyncio\n        if not coro_or_none:\n            return\n        if inspect.iscoroutine(coro_or_none):\n            try:\n                loop = asyncio.get_running_loop()\n                loop.create_task(coro_or_none)\n            except RuntimeError:\n                # No running loop -> run once synchronously\n                asyncio.run(coro_or_none)\n    except Exception:\n        # Don't let telemetry break core writes\n        pass\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# CRDT & Entanglement Lock Registry\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass CRDTRegistry:\n    def __init__(self):\n        self.version_vectors = defaultdict(lambda: defaultdict(int))  # {glyph_id: {agent_id: clock}}\n        self.locks = {}  # {glyph_id: agent_id}\n        self.entanglement_locks = {}  # {entangled_group_id: agent_id}\n\n    def increment_clock(self, glyph_id: str, agent_id: str):\n        self.version_vectors[glyph_id][agent_id] += 1\n        return self.version_vectors[glyph_id]\n\n    def merge_vector(self, glyph_id: str, incoming: Dict[str, int]):\n        local = self.version_vectors[glyph_id]\n        for agent, clock in incoming.items():\n            local[agent] = max(local.get(agent, 0), clock)\n        return local\n\n    def acquire_lock(self, glyph_id: str, agent_id: str) -> bool:\n        if glyph_id in self.locks and self.locks[glyph_id] != agent_id:\n            return False\n        self.locks[glyph_id] = agent_id\n        return True\n\n    def release_lock(self, glyph_id: str, agent_id: str):\n        if self.locks.get(glyph_id) == agent_id:\n            del self.locks[glyph_id]\n\n    def is_locked(self, glyph_id: str) -> Optional[str]:\n        return self.locks.get(glyph_id)\n\n    def acquire_entanglement_lock(self, entangled_group: str, agent_id: str) -> bool:\n        if entangled_group in self.entanglement_locks and self.entanglement_locks[entangled_group] != agent_id:\n            return False\n        self.entanglement_locks[entangled_group] = agent_id\n        return True\n\n    def release_entanglement_lock(self, entangled_group: str, agent_id: str):\n        if self.entanglement_locks.get(entangled_group) == agent_id:\n            del self.entanglement_locks[entangled_group]\n\n    def is_entanglement_locked(self, entangled_group: str) -> Optional[str]:\n        return self.entanglement_locks.get(entangled_group)\n\n\ncrdt_registry = CRDTRegistry()\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Knowledge Graph Writer\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nclass KnowledgeGraphWriter:\n    def __init__(self, container_id: Optional[str] = None, **kwargs):\n        # Explicitly attached UCS container (if any)\n        self._container = None \n        self.container_id = container_id \n\n    def attach_metadata(self, glyph_id: str, metadata: Dict[str, Any]):\n        \"\"\"\n        Attach metadata to a glyph within the currently attached container.\n\n        Args:\n            glyph_id (str): ID of the glyph to modify.\n            metadata (Dict): Metadata to merge into the glyph.\n        \"\"\"\n        if not hasattr(self, \"_container\") or not self._container:\n            print(f\"[KGWriter] \u26a0\ufe0f No container attached.\")\n            return\n\n        found = False\n        for glyph in self._container.get(\"glyphs\", []):\n            if glyph.get(\"id\") == glyph_id:\n                if \"metadata\" not in glyph:\n                    glyph[\"metadata\"] = {}\n                glyph[\"metadata\"].update(metadata)\n                found = True\n                print(f\"[KGWriter] \u2705 Metadata attached to glyph {glyph_id}\")\n                break\n\n        if not found:\n            print(f\"[KGWriter] \u26a0\ufe0f Glyph ID {glyph_id} not found in attached container.\")\n\n    # ---------- helpers ----------\n    def _container_path_for(self, container_id: str) -> str:\n        \"\"\"\n        Resolve the .dc.json path for a container ID.\n        Falls back to the standard containers dir if get_dc_path isn't available.\n        \"\"\"\n        if get_dc_path:\n            p = get_dc_path({\"id\": container_id})\n            if p and os.path.isfile(p):\n                return p\n        # fallback path\n        fallback = f\"backend/modules/dimensions/containers/{container_id}.dc.json\"\n        return fallback\n\n    @staticmethod\n    def store_predictions(container_id: str, predictions: dict):\n        \"\"\"\n        Store prediction results into the knowledge graph or attach to container metadata.\n        \"\"\"\n        if not predictions:\n            return\n\n        logger.info(f\"[KG] Storing predictions for container: {container_id}\")\n        \n        # \ud83d\udd01 Store to in-memory trace or glyph metadata (simplified example)\n        path = f\"backend/modules/dimensions/containers/{container_id}.dc.json\"\n\n        try:\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                container = json.load(f)\n        except FileNotFoundError:\n            logger.warning(f\"[KG] Could not find container file: {path}\")\n            return\n\n        container.setdefault(\"predictions\", {}).update(predictions)\n\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(container, f, indent=2)\n            logger.info(f\"[KG] Predictions saved to container: {path}\")\n    \n    def _safe_load_container(self, path: str) -> dict:\n        if os.path.exists(path):\n            with open(path, \"r\", encoding=\"utf-8\") as f:\n                obj = json.load(f)\n                return obj if isinstance(obj, dict) else {}\n        return {}\n\n    def _safe_save_container(self, path: str, container: dict) -> None:\n        Path(os.path.dirname(path)).mkdir(parents=True, exist_ok=True)\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(container, f, indent=2)\n\n    def inject_node(\n        self,\n        container_id: str,\n        node: dict,\n        *,\n        allow_create: bool = True,\n        commit: bool = True\n    ) -> dict:\n        \"\"\"\n        Persist a KG node into a UCS container file AND into glyph_grid as a 'kg_node'\n        so export_pack will pick it up.\n\n        node: {\"id\": \"...\", \"label\": \"...\", \"domain\": \"...\", \"tags\": [...]}\n        \"\"\"\n        if not isinstance(node, dict) or \"id\" not in node:\n            raise ValueError(\"inject_node: node must be a dict with an 'id'\")\n\n        path = self._container_path_for(container_id)\n        container = self._safe_load_container(path)\n\n        # Create a minimal container if missing\n        if not container:\n            if not allow_create:\n                raise FileNotFoundError(f\"Container not found: {path}\")\n            container = {\n                \"id\": container_id,\n                \"type\": \"container\",\n                \"kind\": node.get(\"kind\", \"fact\"),\n                \"domain\": node.get(\"domain\"),\n                \"meta\": {\n                    \"created_by\": \"SQI\",\n                    \"last_updated\": datetime.utcnow().isoformat(),\n                    \"ghx\": {\"hover\": True, \"collapsed\": True},\n                    \"address\": f\"ucs://knowledge/{node.get('domain','unknown')}/{container_id}\"\n                },\n                \"atoms\": {},\n                \"wormholes\": [\"ucs_hub\"],\n                \"nodes\": [],\n                \"glyphs\": [],\n                \"glyph_grid\": []\n            }\n\n        # Ensure required fields\n        container.setdefault(\"nodes\", [])\n        container.setdefault(\"glyph_grid\", [])\n        container.setdefault(\"meta\", {})\n        meta = container[\"meta\"]\n        meta.setdefault(\"ghx\", {\"hover\": True, \"collapsed\": True})\n\n        # 1) Update/insert in plain nodes (idempotent)\n        replaced = False\n        for i, existing in enumerate(container[\"nodes\"]):\n            if isinstance(existing, dict) and existing.get(\"id\") == node[\"id\"]:\n                container[\"nodes\"][i] = {**existing, **node}\n                replaced = True\n                break\n        if not replaced:\n            container[\"nodes\"].append(dict(node))\n\n        # 2) Update/insert in glyph_grid as a kg_node (what export_pack reads)\n        gg = container[\"glyph_grid\"]\n        # remove any existing kg_node with same id\n        gg = [g for g in gg if not (isinstance(g, dict)\n                                    and g.get(\"type\") == \"kg_node\"\n                                    and g.get(\"metadata\", {}).get(\"id\") == node[\"id\"])]\n        # append a fresh entry\n        gg.append({\n            \"type\": \"kg_node\",\n            \"metadata\": dict(node)\n        })\n        container[\"glyph_grid\"] = gg\n\n        # Touch last_updated\n        meta[\"last_updated\"] = datetime.utcnow().isoformat()\n\n        if commit:\n            self._safe_save_container(path, container)\n\n        return {\n            \"status\": \"ok\",\n            \"container_id\": container_id,\n            \"node_id\": node[\"id\"],\n            \"path\": path\n        }\n\n    def add_node(self, container_id: str, node: dict, **kwargs) -> dict:\n        \"\"\"Back-compat: delegate to inject_node.\"\"\"\n        return self.inject_node(container_id, node, **kwargs)\n\n    @property\n    def container(self):\n        \"\"\"\n        Return the bound container if set, otherwise fall back to UCS active container.\n        \"\"\"\n        if self._container is None:\n            from backend.modules.dimensions.universal_container_system import ucs_runtime\n            self._container = ucs_runtime.get_active_container()\n        return self._container\n        \n    def validate_knowledge_graph(self) -> Dict[str, Any]:\n        from backend.modules.knowledge_graph.indexes.stats_index import build_stats_index\n        glyphs = self.container.get(\"glyph_grid\", [])\n        stats_result = build_stats_index(glyphs)\n\n        return {\n            \"rubric_compliance\": {\n                \"deduplication\": bool(stats_result[\"stats_index\"][\"summary\"][\"frequencies\"]),\n                \"container_awareness\": True,\n                \"semantic_metadata\": any(\"metadata\" in g for g in glyphs),\n                \"timestamps\": all(\"timestamp\" in g for g in glyphs),\n                \"plugin_compatible\": any(\"source_plugin\" in g for g in glyphs),\n                \"search_ready\": True,\n                \"compressed_export\": True,\n                \"dc_injection_ready\": True\n            },\n            \"stats_index\": stats_result[\"stats_index\"],\n            \"total_glyphs\": len(glyphs)\n        }\n\n    def build_node_from_container_for_kg(self, container: dict, *, expand: bool = False) -> dict:\n        \"\"\"\n        HOV1/HOV2/HOV3:\n        - Ensure GHX flags (hover/collapsed) are baked into container meta\n        - Build a KG-ready node with viz hints\n        - Respect lazy expansion (collapsed by default unless expand=True)\n        \"\"\"\n        # HOV1: bake hover/collapse GHX flags into the container meta\n        container = bake_hologram_meta(dict(container or {}))\n        # --- K9b: Hover Geometry Metadata + Entanglement Links ---\n        metadata = container.get(\"metadata\", {})\n\n        # Hover summary and GHX hint (used in HUD overlays)\n        metadata.setdefault(\"hover_summary\", f\"Container: {container.get('id', 'unknown')}\")\n        metadata.setdefault(\"ghx_hint\", \"\u21af Symbolic Container Overview\")\n\n        # Geometry layout type: used in GHX/Atom/Hoberman visuals\n        metadata.setdefault(\"layout_type\", container.get(\"geometry_type\", \"grid\"))\n\n        # Entangled links (\u2194 overlay anchors)\n        if \"entangled_links\" not in metadata:\n            linked = []\n            for glyph in container.get(\"glyphs\", []):\n                entangled = glyph.get(\"entangled_with\")\n                if entangled:\n                    linked.extend(entangled if isinstance(entangled, list) else [entangled])\n            metadata[\"entangled_links\"] = sorted(set(linked))\n\n        # Save metadata back into container\n        container[\"metadata\"] = metadata\n        try:\n            from backend.modules.knowledge_graph.registry.sqi_fastmap_index import sqi_fastmap\n            sqi_fastmap.add_or_update_entry(\n                container_id=container[\"id\"],\n                topic_vector=metadata.get(\"topics\", []),\n                metadata=metadata\n            )\n        except Exception as e:\n            print(f\"\u26a0\ufe0f Failed to update SQI FastMap for {container.get('id')}: {e}\")\n        # HOV2/HOV3: build a KG node payload with GHX viz flags and lazy expansion\n        return make_kg_payload(\n            {\n                \"id\": container.get(\"id\") or container.get(\"container_id\", \"unknown\"),\n                \"meta\": container.get(\"meta\", {}),\n            },\n            expand=expand,  # False by default \u2192 collapsed/lazy\n        )\n\n    # --- NEW: collect UCS/SQI containers as KG nodes (collapsed by default) ---\n    def _collect_sqi_nodes(self) -> list[dict]:\n        \"\"\"\n        Walk the UCS runtime and build KG nodes for all known containers.\n        Collapsed by default (HOV3), with GHX flags baked (HOV1/HOV2).\n        Returns a list of KG node payloads compatible with your export pack.\n        \"\"\"\n        try:\n            from backend.modules.dimensions.universal_container_system import ucs_runtime\n        except Exception as e:\n            print(f\"\u26a0\ufe0f UCS runtime not available for SQI node collection: {e}\")\n            return []\n\n        nodes_out: list[dict] = []\n\n        # Try the common APIs; fall back gracefully\n        try:\n            if hasattr(ucs_runtime, \"list_containers\"):\n                ids = ucs_runtime.list_containers()\n            elif hasattr(ucs_runtime, \"registry\"):\n                ids = list(getattr(ucs_runtime, \"registry\", {}).keys())\n            else:\n                ids = []\n        except Exception as e:\n            print(f\"\u26a0\ufe0f UCS list failed: {e}\")\n            ids = []\n\n        for cid in ids or []:\n            try:\n                # get the actual container object/dict\n                if hasattr(ucs_runtime, \"get_container\"):\n                    c = ucs_runtime.get_container(cid)\n                elif hasattr(ucs_runtime, \"index\"):\n                    c = ucs_runtime.index.get(cid)\n                elif hasattr(ucs_runtime, \"registry\"):\n                    c = ucs_runtime.registry.get(cid)\n                else:\n                    c = None\n\n                if not c:\n                    continue\n\n                # Build a KG node with GHX flags baked, collapsed by default\n                node = self.build_node_from_container_for_kg(c, expand=False)\n                # Your pack uses {'type': 'kg_node', ...}\n                nodes_out.append({\"type\": \"kg_node\", **node})\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Skipped UCS container '{cid}': {e}\")\n\n        return nodes_out\n\n    def export_pack(self, container: dict, out_path: str | Path):\n        \"\"\"\n        Export the container's KG content (from glyph_grid) to a compact JSON pack\n        so it can be reloaded without recomputing. Also appends UCS/SQI containers\n        as collapsed KG nodes with HOV1\u2013HOV3 flags baked.\n\n        This version is aware of inject_node()'s 'kg_node' insertion shape so\n        it will always export the latest injected KG nodes without recomputation.\n        \"\"\"\n        # --- Defensive copy and HOV1\u2013HOV3 injection for the primary container ---\n        container = bake_hologram_meta(dict(container or {}))  # HOV1 flags\n\n        # --- K9b: Hover Geometry Metadata + Entanglement Links ---\n        metadata = container.get(\"metadata\", {})\n\n        # Hover summary and GHX hint (used in HUD overlays)\n        metadata.setdefault(\"hover_summary\", f\"Container: {container.get('id', 'unknown')}\")\n        metadata.setdefault(\"ghx_hint\", \"\u21af Symbolic Container Overview\")\n\n        # Geometry layout type: used in GHX/Atom/Hoberman visuals\n        metadata.setdefault(\"layout_type\", container.get(\"geometry_type\", \"grid\"))\n\n        # Entangled links (\u2194 overlay anchors)\n        if \"entangled_links\" not in metadata:\n            linked = []\n            for glyph in container.get(\"glyphs\", []):\n                entangled = glyph.get(\"entangled_with\")\n                if entangled:\n                    linked.extend(entangled if isinstance(entangled, list) else [entangled])\n            metadata[\"entangled_links\"] = sorted(set(linked))\n\n        # --- K9a: GHX/Hoberman Overlay Fields ---\n        metadata.setdefault(\"ghx_mode\", \"hologram\")\n        metadata.setdefault(\"overlay_layers\", [])\n\n        # If container has atoms or orbitals, set layout_type and overlays\n        if \"atom\" in container.get(\"id\", \"\").lower():\n            metadata[\"layout_type\"] = \"atom\"\n            metadata[\"ghx_mode\"] = \"shell\"\n            metadata[\"overlay_layers\"].append(\"electron_rings\")\n\n        # Hoberman-specific override\n        elif any(\"hoberman\" in tag.lower() for tag in container.get(\"tags\", [])):\n            metadata[\"layout_type\"] = \"hoberman\"\n            metadata[\"ghx_mode\"] = \"expanding_sphere\"\n            metadata[\"overlay_layers\"].append(\"symbolic_expansion\")\n\n        # Add linkPreview from glyphs (electrons or entangled anchors)\n        link_previews = []\n        for g in container.get(\"glyphs\", []):\n            preview_id = g.get(\"linkContainerId\")\n            if preview_id and preview_id not in link_previews:\n                link_previews.append(preview_id)\n        if link_previews:\n            metadata[\"linkPreview\"] = sorted(link_previews)\n\n        # Save metadata back into container\n        container[\"metadata\"] = metadata\n\n        # --- Build collapsed KG node for main container ---\n        kg_node = self.build_node_from_container_for_kg(       # HOV2/HOV3\n            container,\n            expand=False                                        # collapsed by default\n        )\n\n        # --- Extract KG nodes/edges from glyph_grid ---\n        cg = container.get(\"glyph_grid\", [])\n        nodes = []\n        edges = []\n        for g in cg:\n            if not isinstance(g, dict):\n                continue\n            gtype = g.get(\"type\")\n            if gtype == \"kg_node\" and isinstance(g.get(\"metadata\"), dict):\n                nodes.append({**g[\"metadata\"], \"type\": \"kg_node\"})\n            elif gtype == \"kg_edge\" and isinstance(g.get(\"metadata\"), dict):\n                edges.append({\n                    \"src\": g[\"metadata\"].get(\"from\"),\n                    \"dst\": g[\"metadata\"].get(\"to\"),\n                    \"relation\": g[\"metadata\"].get(\"relation\"),\n                })\n\n        pack = {\n            \"id\": container.get(\"id\"),\n            \"name\": container.get(\"name\"),\n            \"symbol\": container.get(\"symbol\", \"\u2754\"),\n            \"glyph_categories\": container.get(\"glyph_categories\", []),\n            \"nodes\": nodes,\n            \"links\": edges,\n        }\n\n        # --- Merge our primary container KG node (dedupe by id) ---\n        existing_nodes = pack.get(\"nodes\", [])\n        idset = {n.get(\"id\") for n in existing_nodes if isinstance(n, dict)}\n        if kg_node.get(\"id\") in idset:\n            existing_nodes = [n for n in existing_nodes if n.get(\"id\") != kg_node.get(\"id\")]\n            idset.discard(kg_node.get(\"id\"))\n        existing_nodes.insert(0, {\"type\": \"kg_node\", **kg_node})\n        idset.add(kg_node.get(\"id\"))\n\n        # --- Collect UCS containers as extra KG nodes (collapsed/lazy by default) ---\n        try:\n            from backend.modules.dimensions.universal_container_system import ucs_runtime\n            ucs_ids = []\n            if hasattr(ucs_runtime, \"list_containers\"):\n                ucs_ids = ucs_runtime.list_containers()\n            elif hasattr(ucs_runtime, \"registry\"):\n                ucs_ids = list(getattr(ucs_runtime, \"registry\", {}).keys())\n\n            for cid in ucs_ids or []:\n                try:\n                    if hasattr(ucs_runtime, \"get_container\"):\n                        uc = ucs_runtime.get_container(cid)\n                    elif hasattr(ucs_runtime, \"index\"):\n                        uc = ucs_runtime.index.get(cid)\n                    elif hasattr(ucs_runtime, \"registry\"):\n                        uc = ucs_runtime.registry.get(cid)\n                    else:\n                        uc = None\n                    if not uc:\n                        continue\n\n                    uc = bake_hologram_meta(dict(uc))  # ensure GHX flags\n                    node = self.build_node_from_container_for_kg(uc, expand=False)\n\n                    nid = node.get(\"id\")\n                    if nid and nid not in idset:\n                        existing_nodes.append({\"type\": \"kg_node\", **node})\n                        idset.add(nid)\n                except Exception as e:\n                    print(f\"\u26a0\ufe0f Skipped UCS container '{cid}': {e}\")\n        except Exception as e:\n            print(f\"\u26a0\ufe0f UCS runtime not available for KG export: {e}\")\n\n        # --- Collect SQI registry containers as extra KG nodes (collapsed) ---\n        try:\n            from backend.modules.sqi.sqi_container_registry import _registry_register\n            for cid, entry in (sqi_registry.index or {}).items():\n                try:\n                    node = make_kg_payload({\"id\": cid, \"meta\": entry.get(\"meta\", {})}, expand=False)\n                    nid = node.get(\"id\")\n                    if nid and nid not in idset:\n                        existing_nodes.append({\"type\": \"kg_node\", **node})\n                        idset.add(nid)\n                except Exception as e:\n                    print(f\"\u26a0\ufe0f Skipped SQI registry entry '{cid}': {e}\")\n        except Exception:\n            pass  # Fine if registry is not available\n\n        # Final assignment\n        pack[\"nodes\"] = existing_nodes\n\n        # --- Write pack to disk ---\n        out_path = Path(out_path)\n        out_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(out_path, \"w\") as f:\n            json.dump(pack, f, indent=2)\n\n        print(f\"\ud83d\udcbe KG export saved to {out_path}\")\n        if ENABLE_WS_BROADCAST:\n            _safe_emit(broadcast_event({\n                \"type\": \"kg_update\",\n                \"domain\": \"physics_core\",\n                \"file\": str(out_path),\n                \"status\": \"saved\"\n            }))\n        return str(out_path)\n\n    def inject_prediction_trace(container: dict, prediction_result: dict, *, origin: str = \"prediction\") -> None:\n        \"\"\"\n        Injects prediction result, contradiction/simplification status,\n        and metadata (confidence, entropy, suggestion) into the container.\n\n        Also tracks full mutation history (trace_id, origin, parent_id),\n        and enables GHX/QFC replay overlay reconstruction.\n        \"\"\"\n\n        # Make sure container has the necessary fields\n        container.setdefault(\"prediction\", {}).update(prediction_result)\n        container.setdefault(\"logic_trace\", [])\n\n        # Detect status and trigger replay flag\n        status = prediction_result.get(\"status\", \"\")\n        if status in {\"contradiction\", \"simplify\"}:\n            container.setdefault(\"metadata\", {})[\"replaySuggested\"] = True\n            container[\"prediction\"][\"trigger_replay\"] = True\n\n        # Generate trace metadata\n        trace_id = str(uuid.uuid4())\n        parent_id = None\n        if container[\"logic_trace\"]:\n            parent_id = container[\"logic_trace\"][-1].get(\"trace_id\")\n\n        trace = {\n            \"type\": \"logic_prediction\",\n            \"trace_id\": trace_id,\n            \"parent_id\": parent_id,\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"origin\": origin,  # e.g. \"initial\", \"mutation\", \"prediction\", \"teleport\"\n            \"status\": status,\n            \"confidence\": prediction_result.get(\"confidence\"),\n            \"entropy\": prediction_result.get(\"entropy\"),\n            \"suggestion\": prediction_result.get(\"suggestion\"),\n            \"mutated_fields\": prediction_result.get(\"mutated_fields\", []),\n            \"mutation_type\": prediction_result.get(\"mutation_type\", None),\n        }\n\n        # Append trace\n        container[\"logic_trace\"].append(trace)\n\n        # Optionally mark last trace for SQI scoring or GHX rendering\n        container.setdefault(\"sqi\", {})[\"last_prediction\"] = trace\n        container.setdefault(\"replay\", {})[\"last_trace_id\"] = trace_id\n\n    def resolve_replay_chain(container: dict, start_id: Optional[str] = None) -> List[dict]:\n        \"\"\"\n        Walks the logic_trace in reverse via parent_id links to reconstruct\n        a full symbolic replay path (e.g. for GHX/QFC overlay or audit).\n        \"\"\"\n        traces = container.get(\"logic_trace\", [])\n        if not traces:\n            return []\n\n        trace_by_id = {t[\"trace_id\"]: t for t in traces if \"trace_id\" in t}\n        current = trace_by_id.get(start_id) if start_id else traces[-1]\n        chain = []\n\n        while current:\n            chain.append(current)\n            pid = current.get(\"parent_id\")\n            current = trace_by_id.get(pid)\n\n        return list(reversed(chain))\n\n    # inside KnowledgeGraphWriter\n    def save_pack_for_container(self, container_id: str, filename: str | None = None):\n        from backend.modules.dimensions.universal_container_system import ucs_runtime\n        c = None\n        if hasattr(ucs_runtime, \"get_container\"):\n            c = ucs_runtime.get_container(container_id)\n        if not c:\n            raise RuntimeError(f\"Unknown container: {container_id}\")\n        name = (filename or c.get(\"name\") or c.get(\"id\") or \"kg_export\").rstrip(\".json\")\n        out = KG_EXPORTS_DIR / f\"{name}.kg.json\"\n        return self.export_pack(c, out)\n\n    def _auto_export_attached(self):\n        \"\"\"\n        If a container is attached, write its KG snapshot to kg_exports/<name>.kg.json.\n        Safe no-op if container is missing or empty.\n        \"\"\"\n        try:\n            c = self.container\n            if not isinstance(c, dict):\n                return\n            name = c.get(\"name\") or c.get(\"id\")\n            if not name:\n                return\n            out = KG_EXPORTS_DIR / f\"{name}.kg.json\"\n            self.export_pack(c, out)\n        except Exception as e:\n            print(f\"\u26a0\ufe0f KG auto-export skipped: {e}\")\n\n    def save_current_pack(self, filename: str | None = None):\n        \"\"\"\n        Manual trigger for saving the current container's KG pack.\n        \"\"\"\n        c = self.container\n        name = (filename or c.get(\"name\") or c.get(\"id\") or \"kg_export\").rstrip(\".json\")\n        out = KG_EXPORTS_DIR / f\"{name}.kg.json\"\n        return self.export_pack(c, out)\n\n    def inject_glyph(\n        self,\n        content: str,\n        glyph_type: str,\n        metadata: Optional[Dict[str, Any]] = None,\n        spatial_location: Optional[str] = None,\n        prediction: Optional[str] = None,\n        plugin: Optional[str] = None,\n        region: Optional[str] = None,\n        coordinates: Optional[Tuple[float, float, float]] = None,\n        forecast_confidence: Optional[float] = None,\n        trace: Optional[str] = None,\n        anchor: Optional[Dict[str, Any]] = None,\n        agent_id: str = \"local\",\n        version_vector: Optional[Dict[str, int]] = None,\n        # NEW:\n        tags: Optional[list] = None,\n    ):\n        # \u2500\u2500 Recursion/rehydration storm guard \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        global _KG_BUSY\n        if _KG_BUSY:\n            # Drop (or queue) to prevent infinite re-entry loops\n            return\n        _KG_BUSY = True\n        try:\n            # \u2500\u2500 Broadcaster (prefer throttled alias; fall back to async enqueue) \u2500\n            _broadcast_sync = None\n            _broadcast_async = None\n            try:\n                # throttled alias accepts a single event dict (sync)\n                from backend.routes.ws.glyphnet_ws import broadcast_event_throttled as _broadcast_sync  # type: ignore\n            except Exception:\n                try:\n                    # async enqueue taking a single event dict\n                    from backend.routes.ws.glyphnet_ws import broadcast_event as _broadcast_async  # type: ignore\n                except Exception:\n                    _broadcast_async = None\n\n            import inspect, asyncio\n\n            def _emit(event_dict: dict):\n                \"\"\"Send event via throttled sync if available; otherwise via async enqueue.\"\"\"\n                try:\n                    if _broadcast_sync:\n                        _broadcast_sync(event_dict)  # sync throttled path\n                        return\n                    if _broadcast_async:\n                        if inspect.iscoroutinefunction(_broadcast_async):\n                            try:\n                                loop = asyncio.get_running_loop()\n                                loop.create_task(_broadcast_async(event_dict))\n                            except RuntimeError:\n                                asyncio.run(_broadcast_async(event_dict))\n                        else:\n                            _broadcast_async(event_dict)\n                    else:\n                        print(f\"[SIM:FALLBACK] Broadcast: {event_dict}\")\n                except Exception:\n                    # Never let broadcast failures bubble into KG write path\n                    pass\n\n            # \u2500\u2500 Original logic (unchanged, just routed through _emit) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n            glyph_id = generate_uuid()\n            timestamp = get_current_timestamp()\n\n            # \ud83d\udd12 Standard Lock Enforcement\n            if not crdt_registry.acquire_lock(glyph_id, agent_id):\n                raise RuntimeError(f\"Glyph {glyph_id} is locked by another agent.\")\n\n            _emit({\n                \"type\": \"lock_acquired\",\n                \"glyph_id\": glyph_id,\n                \"agent_id\": agent_id,\n                \"tags\": [\"\ud83d\udd12\"]\n            })\n\n            # \u2194 Entanglement Lock Enforcement\n            entangled_group = None\n            if metadata and \"entangled_ids\" in metadata:\n                entangled_group = \"|\".join(sorted(metadata[\"entangled_ids\"]))\n                if not crdt_registry.acquire_entanglement_lock(entangled_group, agent_id):\n                    raise RuntimeError(f\"Entangled group {entangled_group} is locked by another agent.\")\n\n                _emit({\n                    \"type\": \"entanglement_lock_acquired\",\n                    \"entangled_group\": entangled_group,\n                    \"agent_id\": agent_id,\n                    \"tags\": [\"\u2194\", \"\ud83d\udd12\"]\n                })\n\n            # \ud83d\udd00 CRDT merge & increment\n            merged_version = crdt_registry.merge_vector(glyph_id, version_vector or {})\n            crdt_registry.increment_clock(glyph_id, agent_id)\n\n            # \ud83d\udee1\ufe0f Wrap string content if necessary\n            if isinstance(content, str):\n                content = {\n                    \"type\": \"symbol\",\n                    \"text\": content,\n                    \"metadata\": metadata or {}\n                }\n\n            # \u2705 Auto-tagging based on glyph operators\n            auto_tags = self._derive_auto_tags(content)\n            final_tags = list(set(auto_tags + (tags or [])))\n\n            entry = {\n                \"id\": glyph_id,\n                \"type\": glyph_type,\n                \"content\": content,\n                \"timestamp\": timestamp,\n                \"metadata\": metadata or {},\n                \"tags\": final_tags,  # manual + auto\n                \"agent_id\": agent_id,\n                \"version_vector\": merged_version\n            }\n            if spatial_location: entry[\"spatial\"] = spatial_location\n            if region: entry[\"region\"] = region\n            if coordinates: entry[\"coordinates\"] = {\"x\": coordinates[0], \"y\": coordinates[1], \"z\": coordinates[2]}\n            if prediction: entry[\"prediction\"] = prediction\n            if forecast_confidence is not None: entry[\"forecast_confidence\"] = forecast_confidence\n            if plugin: entry[\"source_plugin\"] = plugin\n            if trace: entry[\"trace_ref\"] = trace\n            if anchor: entry[\"anchor\"] = anchor\n\n            self._write_to_container(entry)\n            add_to_index(\"knowledge_index.glyph\", entry)\n\n            if anchor:\n                # lazy async anchor broadcast (works in app & CLI)\n                try:\n                    from backend.routes.ws.glyphnet_ws import broadcast_anchor_update  # type: ignore\n                    if inspect.iscoroutinefunction(broadcast_anchor_update):\n                        try:\n                            loop = asyncio.get_running_loop()\n                            loop.create_task(broadcast_anchor_update(glyph_id, anchor))\n                        except RuntimeError:\n                            asyncio.run(broadcast_anchor_update(glyph_id, anchor))\n                    else:\n                        broadcast_anchor_update(glyph_id, anchor)  # sync impl fallback\n                except Exception:\n                    pass\n\n            # \ud83d\udd13 Release locks and emit\n            crdt_registry.release_lock(glyph_id, agent_id)\n            _emit({\n                \"type\": \"lock_released\",\n                \"glyph_id\": glyph_id,\n                \"agent_id\": agent_id\n            })\n\n            if entangled_group:\n                crdt_registry.release_entanglement_lock(entangled_group, agent_id)\n                _emit({\n                    \"type\": \"entanglement_lock_released\",\n                    \"entangled_group\": entangled_group,\n                    \"agent_id\": agent_id\n                })\n\n            return glyph_id\n\n        finally:\n            _KG_BUSY = False\n\n    def write_link_entry(self, source_id: str, target_id: str, direction: str):\n        \"\"\"\n        Adds a directional link edge between containers to the KG.\n        \"\"\"\n        print(f\"\ud83e\udde0 KG: Linking {source_id} \u2192 {target_id} ({direction})\")\n        edge_entry = {\n            \"id\": generate_uuid(),\n            \"type\": \"link\",\n            \"from\": source_id,\n            \"to\": target_id,\n            \"direction\": direction,\n            \"timestamp\": get_current_timestamp(),\n            \"tags\": [\"link\", \"navigation\"],\n            # NEW:\n            \"content\": f\"{source_id} -> {target_id} ({direction})\",\n        }\n        add_to_index(\"knowledge_index.links\", edge_entry)\n\n    def write_entanglement_entry(self, container_a: str, container_b: str):\n        \"\"\"\n        Adds an entanglement edge to the KG.\n        \"\"\"\n        print(f\"\ud83e\udde0 KG: Entangled {container_a} \u2194 {container_b}\")\n        entangle_entry = {\n            \"id\": generate_uuid(),\n            \"type\": \"entanglement\",\n            \"from\": container_a,\n            \"to\": container_b,\n            \"timestamp\": get_current_timestamp(),\n            \"tags\": [\"entangled\", \"\u2194\"],\n            # NEW:\n            \"content\": f\"{container_a} <-> {container_b}\",\n        }\n        add_to_index(\"knowledge_index.entanglements\", entangle_entry)\n\n    def inject_logic_trace_data(trace: dict, logic_prediction: dict, rewrite_suggestion: dict = None):\n        \"\"\"\n        Adds logic prediction and rewrite metadata to CodexTrace entries.\n\n        Parameters:\n            trace (dict): The CodexTrace or glyph trace entry being written.\n            logic_prediction (dict): Dict with keys: 'contradiction', 'confidence', 'suggestion', 'logic_score'.\n            rewrite_suggestion (dict): Optional dict with keys: 'new_glyph', 'goal_match_score', 'rewrite_success_prob'.\n        \"\"\"\n        trace[\"logic_prediction\"] = {\n            \"contradiction\": logic_prediction.get(\"contradiction\", False),\n            \"confidence\": logic_prediction.get(\"confidence\", 0.0),\n            \"suggestion\": logic_prediction.get(\"suggestion\", \"\"),\n            \"logic_score\": logic_prediction.get(\"logic_score\", 0.0),\n        }\n        \n        if rewrite_suggestion:\n            trace[\"rewrite_suggestion\"] = {\n                \"new_glyph\": rewrite_suggestion.get(\"new_glyph\", \"\"),\n                \"goal_match_score\": rewrite_suggestion.get(\"goal_match_score\", 0.0),\n                \"rewrite_success_prob\": rewrite_suggestion.get(\"rewrite_success_prob\", 0.0),\n            }\n\n    def merge_edit(self, glyph_id: str, updates: Dict[str, Any], agent_id: str, version_vector: Dict[str, int]):\n        global _KG_BUSY\n        if _KG_BUSY:\n            return {\"version_vector\": {}}  # safe no-op response\n        try:\n            _KG_BUSY = True\n\n            glyphs = self.container.get(\"glyph_grid\", [])\n            for g in glyphs:\n                if g.get(\"id\") == glyph_id:\n                    prev_state = g.copy()\n                    merged_clock = crdt_registry.merge_vector(glyph_id, version_vector)\n                    local_clock = crdt_registry.version_vectors[glyph_id]\n\n                    # \u26a0\ufe0f Conflict detection: concurrent edits from different agents\n                    if any(version_vector.get(a, 0) > local_clock.get(a, 0) for a in version_vector):\n                        conflict_entry = {\n                            **prev_state,\n                            \"id\": generate_uuid(),\n                            \"type\": \"conflict\",\n                            \"conflict_with\": glyph_id,\n                            \"conflicting_agent\": agent_id,\n                            \"timestamp\": get_current_timestamp(),\n                            \"tags\": [\"\u26a0\ufe0f\", \"conflict\"]\n                        }\n                        self._write_to_container(conflict_entry)\n                        add_to_index(\"knowledge_index.glyph\", conflict_entry)\n\n                    g.update(updates)\n                    g[\"version_vector\"] = dict(merged_clock)\n                    g[\"last_modified_by\"] = agent_id\n                    g[\"last_modified_at\"] = get_current_timestamp()\n                    add_to_index(\"knowledge_index.glyph\", g)\n                    return g\n            raise KeyError(f\"Glyph {glyph_id} not found for merge edit.\")\n\n        finally:\n            _KG_BUSY = False\n\n    # \u2500\u2500 Convenience injectors (kept) \u2500\u2500\n\n    def inject_self_reflection(self, message: str, trigger: str):\n        return self.inject_glyph(content=f\"Reflection: {message}\", glyph_type=\"self_reflection\",\n                                 metadata={\"trigger\": trigger})\n\n    def inject_prediction(self, hypothesis: str, based_on: str, confidence: float = 0.75,\n                          plugin: Optional[str] = None, region: Optional[str] = None,\n                          coords: Optional[Tuple[float, float, float]] = None):\n        return self.inject_glyph(content=hypothesis, glyph_type=\"predictive\",\n                                 metadata={\"based_on\": based_on},\n                                 prediction=\"future\", forecast_confidence=confidence,\n                                 plugin=plugin, region=region, coordinates=coords)\n\n    # \u2500\u2500 KG node/edge helpers \u2500\u2500\n    def add_node(self, node_id: str, label: str, meta: Optional[Dict[str, Any]] = None):\n        return self.inject_glyph(\n            content=f\"KGNode:{node_id} label={label}\",\n            glyph_type=\"kg_node\",\n            metadata={\"node_id\": node_id, \"label\": label, **(meta or {})},\n            plugin=\"KG\"\n        )\n\n    # --- Source/provenance helpers ---\n    def add_source(self, node_id: str, source: Dict[str, Any]):\n        return self.inject_glyph(\n            content=f\"KGSource:{node_id}\",\n            glyph_type=\"kg_source\",\n            metadata={\"node_id\": node_id, **(source or {})},\n            plugin=\"KG\"\n        )\n\n    def link_source(self, node_id: str, source_id: str, relation: str = \"supports\"):\n        self.add_edge(node_id, source_id, relation)\n        try:\n            self.write_link_entry(node_id, source_id, relation)\n        except Exception:\n            pass\n        return self.inject_glyph(\n            content=f\"KGEdge:{node_id}->{source_id} rel={relation}\",\n            glyph_type=\"kg_edge\",\n            metadata={\"from\": node_id, \"to\": source_id, \"relation\": relation},\n            plugin=\"KG\"\n        )\n\n    def add_edge(self, src: str, dst: str, relation: str):\n        self.write_link_entry(src, dst, relation)\n        return self.inject_glyph(\n            content=f\"KGEdge:{src}->{dst} rel={relation}\",\n            glyph_type=\"kg_edge\",\n            metadata={\"from\": src, \"to\": dst, \"relation\": relation},\n            plugin=\"KG\"\n        )\n\n    def add_source(self, node_id: str, source: dict):\n        \"\"\"\n        Attach or update source metadata for a given KG node by emitting a kg_source glyph.\n        source = {\"tier\": \"primary|secondary|tertiary\", \"ref\": \"doi/url\", \"notes\": \"...\"}\n        \"\"\"\n        return self.inject_glyph(\n            content=f\"KGSource:{node_id}\",\n            glyph_type=\"kg_source\",\n            metadata={\"node_id\": node_id, **(source or {})},\n            plugin=\"KG\"\n        )\n\n    def inject_plugin_aware(self, content: str, glyph_type: str, plugin_name: str, metadata: Optional[Dict[str, Any]] = None):\n        return self.inject_glyph(content=content, glyph_type=glyph_type, metadata=metadata, plugin=plugin_name)\n\n    def inject_soullaw_violation(self, rule: str, reason: str, context: Optional[Dict[str, Any]] = None):\n        return self.inject_glyph(\n            content=f\"SoulLaw Violation: {rule} \u2013 {reason}\", glyph_type=\"violation\",\n            metadata={\"rule\": rule, \"type\": \"SoulLaw\", \"reason\": reason, \"context\": context or {}, \"tags\": [\"\ud83d\udcdc\", \"\ud83e\udde0\", \"\u274c\"]},\n            plugin=\"SoulLaw\"\n        )\n\n    def load_domain_pack(self, container_id: str, container: Dict[str, Any]) -> bool:\n        \"\"\"\n        Ingest ANY domain seed (id/nodes/links) into the live KG.\n        \"\"\"\n        nodes = container.get(\"nodes\", [])\n        links = container.get(\"links\", [])\n        if not nodes and not links:\n            return False\n\n        # Add nodes\n        for node in nodes:\n            self.add_node(\n                node[\"id\"],\n                label=node.get(\"label\", node[\"id\"]),\n                meta={\n                    \"source\": container_id,\n                    \"domain\": container.get(\"metadata\", {}).get(\"domain\") or container.get(\"name\") or container_id,\n                    \"category\": node.get(\"cat\"),\n                    **({k: v for k, v in node.items() if k not in (\"id\", \"label\", \"cat\")} ),\n                },\n            )\n\n        # Add links\n        for link in links:\n            self.add_edge(link[\"src\"], link[\"dst\"], link.get(\"relation\", \"relates_to\"))\n\n        # Auto-export snapshot\n        try:\n            c = self.container if getattr(self, \"_container\", None) else container\n            out_path = (Path(os.getenv(\"AION_KG_EXPORT_DIR\", \"\")) if os.getenv(\"AION_KG_EXPORT_DIR\")\n                        else (Path(__file__).resolve().parents[3] / \"backend/modules/dimensions/containers_saved/kg_exports\")) \\\n                    / f\"{container_id}.kg.json\"\n            out_path.parent.mkdir(parents=True, exist_ok=True)\n            self.export_pack(c, out_path)\n        except Exception as e:\n            print(f\"\u26a0\ufe0f KG auto-export failed for {container_id}: {e}\")\n\n        return True  \n\n    def export_pack(self, container: dict, out_path: str):\n        nodes = [g for g in container.get(\"glyph_grid\", []) if g.get(\"type\") == \"kg_node\"]\n        edges = [g for g in container.get(\"glyph_grid\", []) if g.get(\"type\") == \"kg_edge\"]\n        pack = {\n            \"id\": container.get(\"id\"),\n            \"name\": container.get(\"name\"),\n            \"symbol\": container.get(\"symbol\", \"\u2754\"),\n            \"glyph_categories\": container.get(\"glyph_categories\", []),\n            \"nodes\": [n[\"metadata\"] | {\"type\": \"kg_node\"} for n in nodes if \"metadata\" in n],\n            \"links\": [\n                {\n                    \"src\": e[\"metadata\"][\"from\"],\n                    \"dst\": e[\"metadata\"][\"to\"],\n                    \"relation\": e[\"metadata\"][\"relation\"]\n                }\n                for e in edges if \"metadata\" in e\n            ],\n        }\n        import json, os\n        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n        with open(out_path, \"w\") as f:\n            json.dump(pack, f, indent=2)\n        return out_path\n\n    # \u2500\u2500 New: Proof/Drift/Harmonics helpers (Stage C/D integration) \u2500\u2500\n    def write_proof_state(self,\n                          name: str,\n                          status: str,\n                          drift_value: float = 0.0,\n                          depends_on: Optional[List[str]] = None,\n                          metadata: Optional[Dict[str, Any]] = None,\n                          agent_id: str = \"local\") -> str:\n        \"\"\"\n        Persist a proof/lemma state to KG + container for later replay/analytics.\n        \"\"\"\n        content = f\"ProofState:{name} status={status} drift={drift_value}\"\n        md = {\"depends_on\": depends_on or []}\n        if metadata:\n            md.update(metadata)\n        return self.inject_glyph(\n            content=content,\n            glyph_type=\"proof_state\",\n            metadata=md,\n            agent_id=agent_id,\n            plugin=\"SQI\"\n        )\n\n    def write_drift_report(self,\n                           container_id: str,\n                           total_weight: float,\n                           status: str,\n                           gaps: List[Dict[str, Any]],\n                           meta: Optional[Dict[str, Any]] = None,\n                           agent_id: str = \"local\") -> str:\n        \"\"\"\n        Store a drift summary computed by sqi_math_adapter.compute_drift(...)\n        \"\"\"\n        payload = {\n            \"container_id\": container_id,\n            \"total_weight\": total_weight,\n            \"status\": status,\n            \"gaps\": gaps,\n            \"meta\": meta or {},\n        }\n        gid = self.inject_glyph(\n            content=f\"DriftReport:{container_id} weight={total_weight} status={status}\",\n            glyph_type=\"drift_report\",\n            metadata=payload,\n            agent_id=agent_id,\n            plugin=\"SQI\"\n        )\n        add_to_index(\"knowledge_index.drift\", {\"id\": gid, **payload, \"timestamp\": get_current_timestamp()})\n        return gid\n\n    def write_harmonic_suggestions(self,\n                                   target: str,\n                                   suggestions: List[Dict[str, Any]],\n                                   context_container_id: Optional[str] = None,\n                                   agent_id: str = \"local\") -> str:\n        \"\"\"\n        Persist harmonics suggestions e.g. from suggest_harmonics(...)\n        suggestions: [{missing: str, candidates: [{name, score}, ...]}, ...]\n        \"\"\"\n        md = {\n            \"target\": target,\n            \"suggestions\": suggestions,\n            \"container_id\": context_container_id\n        }\n        gid = self.inject_glyph(\n            content=f\"Harmonics:{target}\",\n            glyph_type=\"harmonics_suggestions\",\n            metadata=md,\n            agent_id=agent_id,\n            plugin=\"SQI\"\n        )\n        add_to_index(\"knowledge_index.harmonics\", {\"id\": gid, **md, \"timestamp\": get_current_timestamp()})\n        return gid\n\n    # \u2500\u2500 Internals \u2500\u2500\n    def _derive_auto_tags(self, content: str) -> list:\n        tags = []\n        if \"\u2194\" in content: tags.append(\"entangled\")\n        if \"\u29d6\" in content: tags.append(\"collapse\")\n        if \"\u2b01\" in content: tags.append(\"rewrite\")\n        if \"\ud83e\uddec\" in content: tags.append(\"mutation\")\n        if \"\u269b\" in content: tags.append(\"qglyph\")\n        if content.startswith(\"DriftReport:\"): tags.append(\"drift\")\n        if content.startswith(\"ProofState:\"): tags.append(\"proof\")\n        if content.startswith(\"Harmonics:\"): tags.append(\"harmonics\")\n        return tags\n\n    def _write_to_container(self, entry: Dict[str, Any]):\n        if \"glyph_grid\" not in self.container:\n            self.container[\"glyph_grid\"] = []\n        self.container[\"glyph_grid\"].append(entry)\n        self.container[\"last_updated\"] = datetime.datetime.utcnow().isoformat()\n\n    # \u2500\u2500 Optional: Simple query helpers for dashboards \u2500\u2500\n    def list_by_tag(self, tag: str) -> List[Dict[str, Any]]:\n        return [g for g in self.container.get(\"glyph_grid\", []) if tag in g.get(\"tags\", [])]\n\n    def list_recent(self, limit: int = 20) -> List[Dict[str, Any]]:\n        glyphs = self.container.get(\"glyph_grid\", [])\n        return glyphs[-limit:]\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# write_glyph_entry (updated)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef store_container_metadata(container_path: str, coord: str, metadata: dict):\n        \"\"\"\n        Store metadata into a symbolic container file, such as trace logs, HST info, etc.\n        Appends into container['metadata']['injectionLog'].\n        \"\"\"\n        if not os.path.exists(container_path):\n            logger.warning(f\"[KG] Metadata injection failed \u2014 container not found: {container_path}\")\n            return\n\n        try:\n            with open(container_path, \"r\", encoding=\"utf-8\") as f:\n                container = json.load(f)\n        except Exception as e:\n            logger.error(f\"[KG] Failed to read container {container_path}: {e}\")\n            return\n\n        # Inject into container metadata\n        container.setdefault(\"metadata\", {}).setdefault(\"injectionLog\", []).append({\n            \"coord\": coord,\n            **metadata\n        })\n\n        try:\n            with open(container_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(container, f, indent=2)\n                logger.info(f\"[KG] \u2705 Metadata injected into: {container_path}\")\n        except Exception as e:\n            logger.error(f\"[KG] Failed to write container {container_path}: {e}\")\n\ndef store_generated_glyph(glyph: Dict[str, Any]):\n    \"\"\"\n    Store a generated glyph into the appropriate container and update trace metadata.\n    \"\"\"\n    container_id = glyph.get(\"containerId\") or glyph.get(\"targetContainer\")\n    if not container_id:\n        raise ValueError(\"Generated glyph is missing 'containerId' or 'targetContainer' field\")\n\n    container = load_decrypted_container(container_id)\n    if not container:\n        raise FileNotFoundError(f\"Container '{container_id}' not found or could not be loaded.\")\n\n    # Inject into symbolic trace stream\n    inject_trace_event(container, {\n        \"event\": \"glyph_generated\",\n        \"glyph\": glyph,\n        \"timestamp\": glyph.get(\"timestamp\"),\n        \"source\": \"creative_synthesis\"\n    })\n\n    # Optional Codex/SQI log update\n    codex_metrics.record_glyph_generated(glyph)\n\n    # Persist updated container\n    ucs_runtime.save_container(container_id, container)\n\n    print(f\"\u2705 Stored generated glyph into container '{container_id}'\")\n\ndef write_glyph_entry(\n    glyph: str, g_type: str, g_tag: str, g_value: str, ops_chain: list,\n    context: Dict[str, Any], cost, timestamp: float, tags: list,\n    reasoning_chain: str = None, anchor: Optional[Dict[str, Any]] = None\n):\n    auto_tags = []\n    if \"\u2194\" in glyph: auto_tags.append(\"entangled\")\n    if \"\u29d6\" in glyph: auto_tags.append(\"collapse\")\n    if \"\u2b01\" in glyph: auto_tags.append(\"rewrite\")\n    if \"\ud83e\uddec\" in glyph: auto_tags.append(\"mutation\")\n    if \"\u269b\" in glyph: auto_tags.append(\"qglyph\")\n\n    entry = {\n    \"glyph\": glyph,\n    \"content\": glyph,             \n    \"type\": g_type,\n    \"tag\": g_tag,\n    \"value\": g_value,\n    \"ops_chain\": ops_chain,\n    \"cost\": cost.total(),\n    \"timestamp\": timestamp,\n    \"tags\": list(set(tags + auto_tags)),\n    \"context\": context,\n    \"reasoning_chain\": reasoning_chain or \"No reasoning recorded\",\n    }\n    if anchor:\n        entry[\"anchor\"] = anchor\n\n    # \u2705 Add reasoning entry and update index\n    from backend.modules.knowledge_graph.indexes.reasoning_index import add_reasoning_entry\n    add_reasoning_entry(\n        glyph_id=glyph,\n        reasoning=reasoning_chain or \"Unspecified\",\n        context=context\n    )\n    \n    add_to_index(\"knowledge_index.glyph\", entry)\n\n    # \u2705 Broadcast glyph entry event (safe async emit, no circular import crash)\n    try:\n        from backend.routes.ws.glyphnet_ws import broadcast_event as lazy_broadcast_event\n    except Exception:\n        lazy_broadcast_event = lambda *a, **k: None  # no-op if WS not available\n\n    import inspect, asyncio\n    def _safe_emit(coro_or_none):\n        try:\n            if not coro_or_none:\n                return\n            if inspect.iscoroutine(coro_or_none):\n                try:\n                    loop = asyncio.get_running_loop()\n                    loop.create_task(coro_or_none)\n                except RuntimeError:\n                    asyncio.run(coro_or_none)\n        except Exception:\n            pass\n\n    _safe_emit(lazy_broadcast_event({\n        \"type\": \"glyph_entry\",\n        \"glyph\": glyph,\n        \"tags\": list(set(tags + auto_tags)),\n        \"context\": context,\n        \"anchor\": anchor,\n        \"timestamp\": timestamp,\n    }))\n\n    # \u2705 Broadcast anchor update if present\n    if anchor:\n        create_task(lazy_broadcast_anchor_update(glyph, anchor))\n\n    return entry  # <-- Ensure function return stays intact\ndef get_glyph_trace_for_container(container_id: str) -> list:\n    \"\"\"\n    Retrieve the symbolic glyph trace from a container by its ID.\n    Returns a list of glyphs (or symbolic nodes) for replay / prediction.\n    \"\"\"\n    from backend.modules.dimensions.containers.container_loader import load_container_by_id  # \u2705 Corrected path\n\n    container = load_container_by_id(container_id)\n    if not container:\n        raise ValueError(f\"Container {container_id} not found\")\n\n    # Extract trace from metadata or replay path\n    if \"symbolic_trace\" in container:\n        return container[\"symbolic_trace\"]\n\n    # Optional fallback: GHX field\n    if \"GHX\" in container:\n        return container[\"GHX\"].get(\"trace\", [])\n\n    raise ValueError(f\"No glyph trace found in container {container_id}\")\n\ndef inject_into_trace(trace: List[Dict[str, Any]], entry: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"\n    Inject a symbolic rewrite, prediction, or event into a Codex or KG trace list.\n\n    Args:\n        trace: Existing execution trace list (from a .dc container or live runtime).\n        entry: A dictionary containing the trace event (e.g., rewrite, prediction, etc.).\n\n    Returns:\n        The updated trace list with the new entry appended.\n    \"\"\"\n    if not isinstance(trace, list):\n        trace = []\n\n    if isinstance(entry, dict):\n        trace.append(entry)\n\n    return trace\n\ndef write_glyph_event(\n    event_type: str,\n    event: dict,\n    container_id: str = None\n) -> None:\n    \"\"\"\n    Write a glyph-related event (mutation, prediction, rewrite, etc.)\n    into the knowledge graph trace system.\n\n    Args:\n        event_type: Type of event (e.g. 'dna_mutation', 'rewrite', etc.)\n        event: Dictionary containing event details.\n        container_id: Optional container to tag for context.\n    \"\"\"\n    if not isinstance(event, dict):\n        return\n\n    # Inject into live .dc trace if container is active\n    from backend.modules.runtime.container_runtime import VAULT\n    container = VAULT.get(container_id) if container_id else None\n\n    if container is not None:\n        container.setdefault(\"trace\", {}).setdefault(event_type, []).append(event)\n\n    print(f\"[KGWriter] Event: {event_type} \u2192 {container_id} | {event.get('reason', '')}\")\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Global KG Writer Instance\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n__all__ = [\"kg_writer\", \"store_generated_glyph\"]\nkg_writer = KnowledgeGraphWriter()",
  "meta": {
    "title": "KG Writer Compression Test",
    "description": "Benchmark symbolic ingestion on knowledge_graph_writer.py"
  },
  "trace": {}
}